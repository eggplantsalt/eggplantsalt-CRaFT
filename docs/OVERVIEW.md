# LeRobot é¡¹ç›®æŠ€æœ¯æ–‡ï¿½?
> **ç‰ˆæœ¬**: v0.4.4 | **ä»£ç åº“ç‰ˆï¿½?*: v3.0  
> **æœ€åæ›´ï¿½?*: 2026-02-15

---

## ğŸ“‹ ç›®å½•

- [ç¬¬ä¸€éƒ¨åˆ†ï¼šé¡¹ç›®æ¶æ„åˆ†æ](#ç¬¬ä¸€éƒ¨åˆ†é¡¹ç›®æ¶æ„åˆ†æ)
  - [1.1 é¡¹ç›®æ•´ä½“æ¶æ„](#11-é¡¹ç›®æ•´ä½“æ¶æ„)
  - [1.2 æ¨¡å—è¯¦ç»†è¯´æ˜](#12-æ¨¡å—è¯¦ç»†è¯´æ˜)
  - [1.3 ä»£ç ç»„ç»‡é€»è¾‘](#13-ä»£ç ç»„ç»‡é€»è¾‘)
- [ç¬¬äºŒéƒ¨åˆ†ï¼šå¿«é€Ÿä¸Šæ‰‹æŒ‡å—](#ç¬¬äºŒéƒ¨åˆ†å¿«é€Ÿä¸Šæ‰‹æŒ‡ï¿½?
  - [2.1 ç¯å¢ƒå‡†å¤‡](#21-ç¯å¢ƒå‡†å¤‡)
  - [2.2 é¡¹ç›®å¯åŠ¨æµç¨‹](#22-é¡¹ç›®å¯åŠ¨æµç¨‹)
  - [2.3 è®­ç»ƒå‚æ•°é…ç½®](#23-è®­ç»ƒå‚æ•°é…ç½®)
- [ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ·±å…¥å­¦ä¹ è·¯çº¿](#ç¬¬ä¸‰éƒ¨åˆ†æ·±å…¥å­¦ä¹ è·¯çº¿)
  - [3.1 ä»£ç é˜…è¯»é¡ºåº](#31-ä»£ç é˜…è¯»é¡ºåº)
  - [3.2 æ ¸å¿ƒæ¦‚å¿µç†è§£](#32-æ ¸å¿ƒæ¦‚å¿µç†è§£)
  - [3.3 äºŒæ¬¡å¼€å‘æŒ‡å—](#33-äºŒæ¬¡å¼€å‘æŒ‡ï¿½?

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šé¡¹ç›®æ¶æ„åˆ†ï¿½?
### 1.1 é¡¹ç›®æ•´ä½“æ¶æ„

#### é¡¹ç›®ç›®å½•ï¿½?
```
lerobot/
â”œâ”€â”€ src/lerobot/              # æ ¸å¿ƒæºä»£ï¿½?ï¿½?  â”œâ”€â”€ policies/             # ç­–ç•¥æ¨¡å‹å®ç°ï¼ˆACT, Diffusion, VQ-BeT, TDMPC, Gr00t, Pi0ç­‰ï¼‰
ï¿½?  â”œâ”€â”€ datasets/             # æ•°æ®é›†åŠ è½½ä¸å¤„ç†
ï¿½?  â”œâ”€â”€ robots/               # æœºå™¨äººç¡¬ä»¶æ¥ï¿½?ï¿½?  â”œâ”€â”€ teleoperators/        # é¥æ“ä½œè®¾ï¿½?ï¿½?  â”œâ”€â”€ cameras/              # ç›¸æœºé©±åŠ¨
ï¿½?  â”œâ”€â”€ motors/               # ç”µæœºæ§åˆ¶
ï¿½?  â”œâ”€â”€ processor/            # æ•°æ®å¤„ç†ç®¡é“
ï¿½?  â”œâ”€â”€ envs/                 # ä»¿çœŸç¯å¢ƒï¼ˆAloha, PushT, LIBERO, MetaWorldï¿½?ï¿½?  â”œâ”€â”€ rl/                   # å¼ºåŒ–å­¦ä¹ ç»„ä»¶
ï¿½?  â”œâ”€â”€ async_inference/      # å¼‚æ­¥æ¨ç†æœåŠ¡
ï¿½?  â”œâ”€â”€ configs/              # é…ç½®ç®¡ç†
ï¿½?  â”œâ”€â”€ scripts/              # CLI å‘½ä»¤è¡Œå·¥ï¿½?ï¿½?  â””â”€â”€ utils/                # å·¥å…·å‡½æ•°
â”œâ”€â”€ examples/                 # ç¤ºä¾‹ä»£ç 
ï¿½?  â”œâ”€â”€ training/             # è®­ç»ƒç¤ºä¾‹
ï¿½?  â”œâ”€â”€ tutorial/             # æ•™ç¨‹ä»£ç 
ï¿½?  â”œâ”€â”€ lekiwi/               # LeKiwi æœºå™¨äººç¤ºï¿½?ï¿½?  â””â”€â”€ phone_to_so100/       # æ‰‹æœºé¥æ“ä½œç¤ºï¿½?â”œâ”€â”€ tests/                    # å•å…ƒæµ‹è¯•
â”œâ”€â”€ docs/                     # æ–‡æ¡£
â”œâ”€â”€ benchmarks/               # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”œâ”€â”€ docker/                   # Docker é…ç½®
â””â”€â”€ pyproject.toml            # é¡¹ç›®é…ç½®æ–‡ä»¶
```


#### æ ¸å¿ƒæ¨¡å—åŠèŒï¿½?
| æ¨¡å— | èŒè´£ | å…³é”®æŠ€ï¿½?|
|------|------|----------|
| **policies/** | å®ç°å„ç±»æœºå™¨äººç­–ç•¥æ¨¡ï¿½?| PyTorch, Transformers, Diffusion Models |
| **datasets/** | æ•°æ®é›†åŠ è½½ã€å¤„ç†ã€ç»Ÿè®¡è®¡ï¿½?| Parquet, MP4, HuggingFace Datasets |
| **robots/** | ç»Ÿä¸€æœºå™¨äººç¡¬ä»¶æ¥ï¿½?| Serial, USB, CAN, SDK |
| **teleoperators/** | é¥æ“ä½œè®¾å¤‡é©±ï¿½?| Gamepad, Keyboard, Phone |
| **cameras/** | ç›¸æœºé©±åŠ¨ä¸å›¾åƒé‡‡ï¿½?| OpenCV, RealSense |
| **motors/** | ç”µæœºæ§åˆ¶ï¼ˆDynamixel, Feetech, Damiaoï¿½?| Serial Protocol, CAN Bus |
| **processor/** | æ•°æ®é¢„å¤„ç†ç®¡ï¿½?| Normalization, Tokenization |
| **envs/** | ä»¿çœŸç¯å¢ƒé›†æˆ | Gymnasium, MuJoCo |
| **rl/** | å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶ | Actor-Learner, Replay Buffer |
| **scripts/** | CLI å‘½ä»¤è¡Œå·¥ï¿½?| è®­ç»ƒã€è¯„ä¼°ã€æ•°æ®é‡‡ï¿½?|

#### æ¨¡å—ä¾èµ–å…³ç³»ï¿½?
```mermaid
graph TB
    A[scripts/CLI] --> B[policies]
    A --> C[datasets]
    A --> D[robots]
    A --> E[envs]
    
    B --> F[processor]
    B --> G[configs]
    
    C --> F
    C --> H[utils]
    
    D --> I[motors]
    D --> J[cameras]
    D --> F
    
    K[teleoperators] --> I
    K --> J
    
    E --> F
    E --> H
    
    L[rl] --> B
    L --> C
    L --> E
    
    M[async_inference] --> B
    M --> D
    
    style A fill:#e1f5ff
    style B fill:#ffe1e1
    style C fill:#e1ffe1
    style D fill:#fff5e1
```

#### æ•°æ®æµå›¾

```mermaid
flowchart LR
    A[æœºå™¨ï¿½?ç¯å¢ƒ] -->|è§‚æµ‹| B[Processor Pipeline]
    B -->|å¤„ç†åæ•°æ®| C[Policy Model]
    C -->|åŠ¨ä½œ| D[Processor Pipeline]
    D -->|æ‰§è¡ŒåŠ¨ä½œ| A
    
    E[Dataset] -->|è®­ç»ƒæ•°æ®| B
    C -->|ä¿å­˜| F[Checkpoint]
    
    style A fill:#ffebcc
    style C fill:#ccf2ff
    style E fill:#d4edda
```

### 1.2 æ¨¡å—è¯¦ç»†è¯´æ˜

#### 1.2.1 Policies æ¨¡å—

**åŠŸèƒ½æè¿°**ï¼šå®ç°å¤šç§æœºå™¨äººç­–ç•¥æ¨¡å‹ï¼Œæ”¯æŒæ¨¡ä»¿å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ å’Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¿½?
**æ”¯æŒçš„ç­–ï¿½?*ï¿½?
| ç­–ç•¥ | ç±»å‹ | ç‰¹ç‚¹ | é…ç½®æ–‡ä»¶ |
|------|------|------|----------|
| **ACT** | æ¨¡ä»¿å­¦ä¹  | Transformer + CVAEï¼Œé€‚åˆåŒè‡‚æ“ä½œ | `configuration_act.py` |
| **Diffusion** | æ¨¡ä»¿å­¦ä¹  | æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå¹³æ»‘è½¨ï¿½?| `configuration_diffusion.py` |
| **VQ-BeT** | æ¨¡ä»¿å­¦ä¹  | å‘é‡é‡åŒ– + Transformer | `configuration_vqbet.py` |
| **TDMPC** | å¼ºåŒ–å­¦ä¹  | æ¨¡å‹é¢„æµ‹æ§åˆ¶ | `configuration_tdmpc.py` |
| **Gr00t** | VLA | NVIDIA å¤§æ¨¡å‹ï¼Œæ”¯æŒå¤šæ¨¡ï¿½?| `configuration_groot.py` |
| **Pi0/Pi0.5** | VLA | Physical Intelligence é¢„è®­ç»ƒæ¨¡ï¿½?| `configuration_pi0.py` |
| **SmolVLA** | VLA | è½»é‡çº§è§†ï¿½?è¯­è¨€-åŠ¨ä½œæ¨¡å‹ | `configuration_smolvla.py` |
| **XVLA** | VLA | è·¨æ¨¡ï¿½?VLA æ¨¡å‹ | `configuration_xvla.py` |

**å…³é”®ï¿½?å‡½æ•°**ï¿½?
```python
# src/lerobot/policies/pretrained.py
class PreTrainedPolicy:
    \"\"\"æ‰€æœ‰ç­–ç•¥çš„åŸºç±»\"\"\"
    def select_action(self, observation: dict) -> torch.Tensor:
        \"\"\"æ ¹æ®è§‚æµ‹é€‰æ‹©åŠ¨ä½œ\"\"\"
        pass
    
    def forward(self, batch: dict) -> dict:
        \"\"\"å‰å‘ä¼ æ’­ï¼Œç”¨äºè®­ç»ƒ\"\"\"
        pass
```

**æ¥å£å®šä¹‰**ï¿½?- è¾“å…¥ï¼š`observation` å­—å…¸ï¼ˆåŒ…å«å›¾åƒã€çŠ¶æ€ç­‰ï¿½?- è¾“å‡ºï¼š`ction` å¼ é‡ï¼ˆæœºå™¨äººåŠ¨ä½œï¿½?
#### 1.2.2 Datasets æ¨¡å—

**åŠŸèƒ½æè¿°**ï¼šLeRobotDataset æ ¼å¼çš„æ•°æ®é›†åŠ è½½ã€å¤„ç†ã€å¯è§†åŒ–å’Œå·¥å…·ï¿½?
**æ ¸å¿ƒï¿½?*ï¿½?
```python
# src/lerobot/datasets/lerobot_dataset.py
class LeRobotDataset:
    \"\"\"LeRobot æ ‡å‡†æ•°æ®é›†æ ¼å¼\"\"\"
    def __init__(self, repo_id: str, root: Path = None):
        # ï¿½?HuggingFace Hub åŠ è½½æ•°æ®ï¿½?        pass
    
    def __getitem__(self, idx: int) -> dict:
        # è¿”å›å•ä¸ªæ ·æœ¬ï¼ˆè‡ªåŠ¨è§£ç è§†é¢‘ï¼‰
        pass
```

**æ•°æ®æ ¼å¼**ï¿½?- **è§†é¢‘**ï¼šMP4 æ ¼å¼ï¼ˆH.264/HEVC ç¼–ç ï¿½?- **çŠ¶ï¿½?åŠ¨ä½œ**ï¼šParquet æ–‡ä»¶
- **å…ƒæ•°ï¿½?*ï¼šJSON æ ¼å¼ï¼ˆinfo.json, stats.jsonï¿½?
**å…³é”®åŠŸèƒ½**ï¿½?- `compute_stats.py`ï¼šè®¡ç®—æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ï¿½?- `dataset_tools.py`ï¼šæ•°æ®é›†ç¼–è¾‘å·¥å…·ï¼ˆåˆ é™¤ã€åˆå¹¶ã€åˆ†å‰²ï¼‰
- `image_writer.py`ï¼šå¼‚æ­¥å›¾åƒå†™ï¿½?- `video_utils.py`ï¼šè§†é¢‘ç¼–è§£ç 

#### 1.2.3 Robots æ¨¡å—

**åŠŸèƒ½æè¿°**ï¼šæä¾›ç»Ÿä¸€ï¿½?`Robot` æ¥å£ï¼Œæ”¯æŒå¤šç§ç¡¬ä»¶å¹³å°ï¿½?
**åŸºç±»å®šä¹‰**ï¿½?
```python
# src/lerobot/robots/robot.py
class Robot(abc.ABC):
    @abc.abstractmethod
    def connect(self):
        \"\"\"è¿æ¥æœºå™¨äºº\"\"\"
        pass
    
    @abc.abstractmethod
    def get_observation(self) -> RobotObservation:
        \"\"\"è·å–è§‚æµ‹\"\"\"
        pass
    
    @abc.abstractmethod
    def send_action(self, action: RobotAction):
        \"\"\"å‘é€åŠ¨ä½œ\"\"\"
        pass
```

**æ”¯æŒçš„æœºå™¨äºº**ï¿½?- SO100/SO101ï¼ˆä½æˆæœ¬æœºæ¢°è‡‚ï¼‰
- Kochï¼ˆåŒè‡‚æœºå™¨äººï¿½?- LeKiwiï¼ˆç§»åŠ¨æœºå™¨äººï¿½?- Reachy2ï¼ˆäººå½¢æœºå™¨äººï¿½?- Unitree G1ï¼ˆäººå½¢æœºå™¨äººï¿½?- OpenARMï¼ˆå¼€æºæœºæ¢°è‡‚ï¿½?
#### 1.2.4 Processor æ¨¡å—

**åŠŸèƒ½æè¿°**ï¼šæ•°æ®å¤„ç†ç®¡é“ï¼Œè´Ÿè´£è§‚æµ‹å’ŒåŠ¨ä½œçš„é¢„å¤„ç†ã€åå¤„ç†ï¿½?
**æ ¸å¿ƒç»„ä»¶**ï¿½?
```python
# src/lerobot/processor/pipeline.py
class DataProcessorPipeline:
    \"\"\"æ•°æ®å¤„ç†ç®¡é“\"\"\"
    def __init__(self, steps: list[ProcessorStep]):
        self.steps = steps
    
    def __call__(self, data: dict) -> dict:
        for step in self.steps:
            data = step(data)
        return data
```

**å¸¸ç”¨å¤„ç†ï¿½?*ï¿½?- `NormalizeProcessor`ï¼šå½’ä¸€ï¿½?- `ObservationProcessor`ï¼šè§‚æµ‹å¤„ï¿½?- `DeviceProcessor`ï¼šè®¾å¤‡è½¬æ¢ï¼ˆCPU/GPUï¿½?- `TokenizerProcessor`ï¼šæ–‡æœ¬åˆ†ï¿½?
### 1.3 ä»£ç ç»„ç»‡é€»è¾‘

#### å‘½åè§„èŒƒ

- **ç±»å**ï¼šå¤§é©¼å³°ï¼ˆ`LeRobotDataset`, `PreTrainedPolicy`ï¿½?- **å‡½æ•°ï¿½?*ï¼šå°å†™ä¸‹åˆ’çº¿ï¼ˆ`get_observation`, `send_action`ï¿½?- **å¸¸é‡**ï¼šå¤§å†™ä¸‹åˆ’çº¿ï¼ˆ`CODEBASE_VERSION`, `HF_LEROBOT_HOME`ï¿½?- **é…ç½®ï¿½?*ï¼š`Configuration` åç¼€ï¼ˆ`ACTConfig`, `DiffusionConfig`ï¿½?
#### è®¾è®¡æ¨¡å¼

1. **å·¥å‚æ¨¡å¼**ï¼š`actory.py` æ–‡ä»¶ç”¨äºåˆ›å»ºå¯¹è±¡
   - `policies/factory.py`ï¼šåˆ›å»ºç­–ï¿½?   - `datasets/factory.py`ï¼šåˆ›å»ºæ•°æ®é›†
   - `envs/factory.py`ï¼šåˆ›å»ºç¯ï¿½?
2. **æ³¨å†Œè¡¨æ¨¡ï¿½?*ï¼š`ProcessorStepRegistry` ç”¨äºæ³¨å†Œå¤„ç†ï¿½?
3. **æŠ½è±¡åŸºç±»**ï¼š`Robot`, `PreTrainedPolicy` å®šä¹‰æ¥å£

#### é…ç½®ç®¡ç†

ä½¿ç”¨ `draccus` åº“è¿›è¡Œé…ç½®ç®¡ç†ï¼š

```python
# src/lerobot/configs/train.py
@dataclass
class TrainPipelineConfig:
    policy: PolicyConfig
    dataset: DatasetConfig
    training: TrainingConfig
    eval: EvalConfig
```

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šå¿«é€Ÿä¸Šæ‰‹æŒ‡ï¿½?
### 2.1 ç¯å¢ƒå‡†å¤‡

#### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šWindows 10/11, Ubuntu 20.04+, macOS 12+
- **Python**ï¿½?= 3.10
- **CUDA**ï¿½?= 11.8ï¼ˆå¯é€‰ï¼Œç”¨äº GPU åŠ é€Ÿï¼‰
- **å†…å­˜**ï¿½?= 16GB RAM
- **å­˜å‚¨**ï¿½?= 50GB å¯ç”¨ç©ºé—´

#### ä¾èµ–é¡¹åˆ—ï¿½?
**æ ¸å¿ƒä¾èµ–**ï¿½?- PyTorch >= 2.2.1
- Transformers >= 4.57.1
- Datasets >= 4.0.0
- Hugging Face Hub >= 0.34.2
- OpenCV >= 4.9.0

**å¯é€‰ä¾ï¿½?*ï¼ˆæ ¹æ®éœ€æ±‚å®‰è£…ï¼‰ï¿½?- `lerobot[dynamixel]`ï¼šDynamixel ç”µæœºæ”¯æŒ
- `lerobot[intelrealsense]`ï¼šRealSense ç›¸æœºæ”¯æŒ
- `lerobot[aloha]`ï¼šAloha ä»¿çœŸç¯å¢ƒ
- `lerobot[groot]`ï¼šGr00t æ¨¡å‹æ”¯æŒ
- `lerobot[all]`ï¼šæ‰€æœ‰åŠŸï¿½?
#### ç¯å¢ƒé…ç½®æ­¥éª¤

**æ­¥éª¤ 1ï¼šå®‰ï¿½?Python ç¯å¢ƒ**

```powershell
# æ£€ï¿½?Python ç‰ˆæœ¬
python --version

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv lerobot_env

# æ¿€æ´»è™šæ‹Ÿç¯ï¿½?.\lerobot_env\Scripts\activate
```

**æ­¥éª¤ 2ï¼šå®‰ï¿½?LeRobot**

```powershell
# åŸºç¡€å®‰è£…
pip install lerobot

# æˆ–ä»æºç å®‰è£…ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
git clone https://github.com/huggingface/lerobot.git
cd lerobot
pip install -e .

# å®‰è£…ç‰¹å®šåŠŸèƒ½
pip install lerobot[aloha]  # ä»¿çœŸç¯å¢ƒ
pip install lerobot[groot]  # Gr00t æ¨¡å‹
```

**æ­¥éª¤ 3ï¼šéªŒè¯å®‰ï¿½?*

```powershell
# æŸ¥çœ‹ç‰ˆæœ¬ä¿¡æ¯
lerobot-info

# è¾“å‡ºç¤ºä¾‹ï¿½?# LeRobot version: 0.4.4
# Python version: 3.10.x
# PyTorch version: 2.2.1
```

#### å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹ï¿½?
ğŸ’¡ **é—®é¢˜ 1ï¼šCUDA ä¸å¯ï¿½?*

```powershell
# æ£€ï¿½?CUDA æ˜¯å¦å¯ç”¨
python -c "import torch; print(torch.cuda.is_available())"

# è§£å†³æ–¹æ¡ˆï¼šå®‰è£…å¯¹ï¿½?CUDA ç‰ˆæœ¬ï¿½?PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

ğŸ’¡ **é—®é¢˜ 2ï¼šç›¸æœºé©±åŠ¨å®‰è£…å¤±ï¿½?*

```powershell
# RealSense ç›¸æœºéœ€è¦é¢å¤–é©±ï¿½?# Windows: ä¸‹è½½ Intel RealSense SDK
# https://github.com/IntelRealSense/librealsense/releases
```

âš ï¸ **é—®é¢˜ 3ï¼šæƒé™é”™è¯¯ï¼ˆä¸²å£è®¿é—®ï¿½?*

```powershell
# Windows: ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ
# Linux: æ·»åŠ ç”¨æˆ·ï¿½?dialout ï¿½?sudo usermod -a -G dialout $USER
```

**æ£€æŸ¥æ¸…ï¿½?*ï¿½?- [ ] Python >= 3.10 å·²å®‰ï¿½?- [ ] LeRobot å®‰è£…æˆåŠŸ
- [ ] `lerobot-info` å‘½ä»¤å¯æ‰§ï¿½?- [ ] PyTorch å¯æ­£å¸¸å¯¼ï¿½?- [ ] CUDA å¯ç”¨ï¼ˆå¦‚éœ€ GPUï¿½?

### 2.2 é¡¹ç›®å¯åŠ¨æµç¨‹

#### åœºæ™¯ 1ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†

```powershell
# ï¿½?HuggingFace Hub åŠ è½½é¢„è®­ç»ƒæ¨¡ï¿½?python -c "
from lerobot.policies.pretrained import PreTrainedPolicy

# åŠ è½½ ACT ç­–ç•¥
policy = PreTrainedPolicy.from_pretrained('lerobot/act_aloha_sim_transfer_cube_human')

# å‡†å¤‡è§‚æµ‹æ•°æ®
import torch
observation = {
    'observation.images.top': torch.randn(1, 3, 480, 640),
    'observation.state': torch.randn(1, 14)
}

# æ¨ç†
action = policy.select_action(observation)
print(f'Action shape: {action.shape}')
"
```

#### åœºæ™¯ 2ï¼šåœ¨ä»¿çœŸç¯å¢ƒä¸­è¯„ä¼°ç­–ï¿½?
```powershell
# è¯„ä¼° ACT ç­–ç•¥ï¿½?Aloha ç¯å¢ƒ
lerobot-eval \
  --policy.path=lerobot/act_aloha_sim_transfer_cube_human \
  --env.type=aloha \
  --env.task=AlohaTransferCube-v0 \
  --eval.n_episodes=10 \
  --eval.batch_size=10
```

**å‚æ•°è¯´æ˜**ï¿½?- `--policy.path`ï¼šæ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°ï¿½?Hubï¿½?- `--env.type`ï¼šç¯å¢ƒç±»å‹ï¼ˆaloha, pusht, libero, metaworldï¿½?- `--env.task`ï¼šä»»åŠ¡åï¿½?- `--eval.n_episodes`ï¼šè¯„ä¼°å›åˆæ•°
- `--eval.batch_size`ï¼šæ‰¹æ¬¡å¤§ï¿½?
#### åœºæ™¯ 3ï¼šè®­ç»ƒæ–°ç­–ç•¥

```powershell
# è®­ç»ƒ ACT ç­–ç•¥
lerobot-train \
  --policy=act \
  --dataset.repo_id=lerobot/aloha_sim_transfer_cube_human \
  --training.offline_steps=100000 \
  --training.batch_size=8 \
  --training.lr=1e-4 \
  --training.save_checkpoint=True \
  --training.save_freq=10000 \
  --output_dir=outputs/act_training
```

**å…³é”®å‚æ•°**ï¿½?- `--policy`ï¼šç­–ç•¥ç±»å‹ï¼ˆact, diffusion, vqbet, tdmpcï¿½?- `--dataset.repo_id`ï¼šæ•°æ®é›† ID
- `--training.offline_steps`ï¼šè®­ç»ƒæ­¥ï¿½?- `--training.batch_size`ï¼šæ‰¹æ¬¡å¤§ï¿½?- `--training.lr`ï¼šå­¦ä¹ ç‡
- `--output_dir`ï¼šè¾“å‡ºç›®ï¿½?
#### åœºæ™¯ 4ï¼šæ•°æ®é‡‡é›†ï¼ˆçœŸå®æœºå™¨äººï¼‰

```powershell
# æ­¥éª¤ 1ï¼šæŸ¥æ‰¾ç›¸ï¿½?lerobot-find-cameras

# æ­¥éª¤ 2ï¼šæŸ¥æ‰¾ç”µæœºç«¯ï¿½?lerobot-find-port

# æ­¥éª¤ 3ï¼šæ ¡å‡†ç”µï¿½?lerobot-calibrate --robot=so100

# æ­¥éª¤ 4ï¼šé¥æ“ä½œæµ‹è¯•
lerobot-teleoperate --robot=so100 --teleop=gamepad

# æ­¥éª¤ 5ï¼šè®°å½•æ•°ï¿½?lerobot-record \
  --robot=so100 \
  --fps=30 \
  --repo-id=my_username/my_dataset \
  --num-episodes=50 \
  --warmup-time-s=3 \
  --episode-time-s=30 \
  --reset-time-s=5
```

#### åœºæ™¯ 5ï¼šå¯è§†åŒ–æ•°æ®ï¿½?
```powershell
# å¯åŠ¨æ•°æ®é›†å¯è§†åŒ–å·¥å…·
lerobot-dataset-viz --repo-id=lerobot/aloha_sim_transfer_cube_human

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:8000
```

#### å¤šåœºæ™¯å¯åŠ¨é…ç½®å®ï¿½?
**é…ç½®æ–‡ä»¶ç¤ºä¾‹**ï¼ˆ`config.yaml`ï¼‰ï¼š

```yaml
# è®­ç»ƒé…ç½®
policy:
  name: act
  n_obs_steps: 1
  chunk_size: 100
  n_action_steps: 100

dataset:
  repo_id: lerobot/aloha_sim_transfer_cube_human
  image_transforms:
    enable: true
    max_num_transforms: 3

training:
  offline_steps: 100000
  batch_size: 8
  lr: 1e-4
  lr_scheduler: cosine
  grad_clip_norm: 10
  save_checkpoint: true
  save_freq: 10000

eval:
  n_episodes: 10
  batch_size: 10
```

**ä½¿ç”¨é…ç½®æ–‡ä»¶**ï¿½?
```powershell
lerobot-train --config=config.yaml
```

**æ£€æŸ¥æ¸…ï¿½?*ï¿½?- [ ] æ¨¡å‹åŠ è½½æˆåŠŸ
- [ ] æ•°æ®é›†å¯è®¿é—®
- [ ] GPU å¯ç”¨ï¼ˆå¦‚éœ€è¦ï¼‰
- [ ] è¾“å‡ºç›®å½•å·²åˆ›ï¿½?- [ ] æ—¥å¿—æ­£å¸¸è¾“å‡º

### 2.3 è®­ç»ƒå‚æ•°é…ç½®

#### æ ¸å¿ƒè®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤ï¿½?| å–å€¼èŒƒï¿½?| åŠŸèƒ½å½±å“ |
|------|--------|----------|----------|
| `offline_steps` | 100000 | 10000-1000000 | è®­ç»ƒæ€»æ­¥æ•°ï¼Œå½±å“æ¨¡å‹æ”¶æ•› |
| `batch_size` | 8 | 1-128 | æ‰¹æ¬¡å¤§å°ï¼Œå½±å“æ˜¾å­˜å ç”¨å’Œè®­ç»ƒç¨³å®šï¿½?|
| `lr` | 1e-4 | 1e-6 - 1e-3 | å­¦ä¹ ç‡ï¼Œè¿‡å¤§å¯¼è‡´ä¸ç¨³å®šï¼Œè¿‡å°æ”¶æ•›ï¿½?|
| `grad_clip_norm` | 10 | 1-100 | æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ï¿½?|
| `eval_freq` | 10000 | 1000-50000 | è¯„ä¼°é¢‘ç‡ |
| `save_freq` | 10000 | 1000-50000 | ä¿å­˜æ£€æŸ¥ç‚¹é¢‘ç‡ |

#### ç­–ç•¥ç‰¹å®šå‚æ•°

**ACT ç­–ç•¥**ï¿½?
```yaml
policy:
  name: act
  n_obs_steps: 1          # è§‚æµ‹å†å²é•¿åº¦
  chunk_size: 100         # åŠ¨ä½œåºåˆ—é•¿åº¦
  n_action_steps: 100     # é¢„æµ‹åŠ¨ä½œæ­¥æ•°
  dim_model: 512          # Transformer ç»´åº¦
  n_heads: 8              # æ³¨æ„åŠ›å¤´ï¿½?  dim_feedforward: 3200   # å‰é¦ˆç½‘ç»œç»´åº¦
  n_encoder_layers: 4     # ç¼–ç å™¨å±‚ï¿½?  n_decoder_layers: 7     # è§£ç å™¨å±‚ï¿½?  kl_weight: 10.0         # KL æ•£åº¦æƒé‡
```

**Diffusion ç­–ç•¥**ï¿½?
```yaml
policy:
  name: diffusion
  n_obs_steps: 2          # è§‚æµ‹å†å²é•¿åº¦
  horizon: 16             # é¢„æµ‹æ—¶åŸŸ
  n_action_steps: 8       # æ‰§è¡ŒåŠ¨ä½œæ­¥æ•°
  num_inference_steps: 10 # æ¨ç†æ‰©æ•£æ­¥æ•°
  down_dims: [256, 512, 1024]  # U-Net ä¸‹é‡‡æ ·ç»´ï¿½?```

**VQ-BeT ç­–ç•¥**ï¿½?
```yaml
policy:
  name: vqbet
  n_obs_steps: 1
  chunk_size: 100
  n_vqvae_training_steps: 20000  # VQ-VAE é¢„è®­ç»ƒæ­¥ï¿½?  vq_n_embed: 16          # ç æœ¬å¤§å°
  vq_embed_dim: 256       # åµŒå…¥ç»´åº¦
```

#### å¸¸ç”¨å‚æ•°æ¨¡æ¿

**å¿«é€ŸåŸå‹ï¼ˆå°æ•°æ®é›†ï¿½?*ï¿½?
```yaml
training:
  offline_steps: 10000
  batch_size: 16
  lr: 3e-4
  eval_freq: 1000
  save_freq: 5000
```

**æ ‡å‡†è®­ç»ƒï¼ˆä¸­ç­‰æ•°æ®é›†ï¿½?*ï¿½?
```yaml
training:
  offline_steps: 100000
  batch_size: 8
  lr: 1e-4
  eval_freq: 10000
  save_freq: 10000
```

**å¤§è§„æ¨¡è®­ç»ƒï¼ˆå¤§æ•°æ®é›†ï¿½?*ï¿½?
```yaml
training:
  offline_steps: 500000
  batch_size: 32
  lr: 5e-5
  lr_scheduler: cosine
  warmup_steps: 5000
  eval_freq: 25000
  save_freq: 25000
  use_amp: true  # æ··åˆç²¾åº¦è®­ç»ƒ
```

#### è°ƒä¼˜å»ºè®®ä¸æœ€ä½³å®ï¿½?
ğŸ’¡ **å­¦ä¹ ç‡è°ƒï¿½?*ï¿½?- ï¿½?`1e-4` å¼€ï¿½?- è§‚å¯ŸæŸå¤±æ›²çº¿ï¼Œå¦‚æœéœ‡è¡é™ä½å­¦ä¹ ç‡
- ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆcosine, linearï¿½?
ğŸ’¡ **æ‰¹æ¬¡å¤§å°é€‰æ‹©**ï¿½?- GPU æ˜¾å­˜ 8GBï¼š`atch_size=4`
- GPU æ˜¾å­˜ 16GBï¼š`atch_size=8`
- GPU æ˜¾å­˜ 24GB+ï¼š`atch_size=16-32`

ğŸ’¡ **æ•°æ®å¢å¼º**ï¿½?
```yaml
dataset:
  image_transforms:
    enable: true
    max_num_transforms: 3
    random_crop: true
    brightness: [0.8, 1.2]
    contrast: [0.8, 1.2]
```

âš ï¸ **å¸¸è§é™·é˜±**ï¿½?- å­¦ä¹ ç‡è¿‡å¤§å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
- æ‰¹æ¬¡å¤§å°è¿‡å°å¯¼è‡´æ¢¯åº¦å™ªå£°ï¿½?- æœªä½¿ç”¨æ¢¯åº¦è£å‰ªå¯¼è‡´æ¢¯åº¦çˆ†ï¿½?- è¯„ä¼°é¢‘ç‡è¿‡ä½é”™è¿‡æœ€ä½³æ¨¡ï¿½?
**æ£€æŸ¥æ¸…ï¿½?*ï¿½?- [ ] å­¦ä¹ ç‡è®¾ç½®åˆï¿½?- [ ] æ‰¹æ¬¡å¤§å°é€‚é…æ˜¾å­˜
- [ ] æ¢¯åº¦è£å‰ªå·²å¯ï¿½?- [ ] è¯„ä¼°å’Œä¿å­˜é¢‘ç‡åˆï¿½?- [ ] æ•°æ®å¢å¼ºé…ç½®æ­£ç¡®

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ·±å…¥å­¦ä¹ è·¯ï¿½?
### 3.1 ä»£ç é˜…è¯»é¡ºåº

#### æ¨èé˜…è¯»è·¯å¾„

**é˜¶æ®µ 1ï¼šç†è§£æ•°æ®æµï¿½?-2 å¤©ï¼‰**

1. `src/lerobot/datasets/lerobot_dataset.py` - æ•°æ®é›†åŠ ï¿½?2. `src/lerobot/processor/pipeline.py` - æ•°æ®å¤„ç†ç®¡é“
3. `examples/dataset/load_lerobot_dataset.py` - æ•°æ®åŠ è½½ç¤ºä¾‹

**å­¦ä¹ ç›®æ ‡**ï¿½?- ç†è§£ LeRobotDataset æ ¼å¼
- æŒæ¡æ•°æ®åŠ è½½æµç¨‹
- äº†è§£æ•°æ®é¢„å¤„ç†æ­¥ï¿½?
**é˜¶æ®µ 2ï¼šæŒæ¡ç­–ç•¥æ¨¡å‹ï¼ˆ3-5 å¤©ï¼‰**

1. `src/lerobot/policies/pretrained.py` - ç­–ç•¥åŸºç±»
2. `src/lerobot/policies/act/modeling_act.py` - ACT æ¨¡å‹å®ç°
3. `src/lerobot/policies/diffusion/modeling_diffusion.py` - Diffusion æ¨¡å‹
4. `examples/tutorial/act/act_training_example.py` - è®­ç»ƒç¤ºä¾‹

**å­¦ä¹ ç›®æ ‡**ï¿½?- ç†è§£ç­–ç•¥æ¥å£è®¾è®¡
- æŒæ¡ ACT ï¿½?Diffusion åŸç†
- èƒ½å¤Ÿè®­ç»ƒå’Œè¯„ä¼°æ¨¡ï¿½?
**é˜¶æ®µ 3ï¼šæœºå™¨äººæ§åˆ¶ï¿½?-3 å¤©ï¼‰**

1. `src/lerobot/robots/robot.py` - æœºå™¨äººåŸºï¿½?2. `src/lerobot/robots/so_follower/so_follower.py` - SO100 å®ç°
3. `src/lerobot/motors/motors_bus.py` - ç”µæœºæ§åˆ¶
4. `examples/phone_to_so100/teleoperate.py` - é¥æ“ä½œç¤ºï¿½?
**å­¦ä¹ ç›®æ ‡**ï¿½?- ç†è§£æœºå™¨äººæ¥ï¿½?- æŒæ¡ç”µæœºæ§åˆ¶åŸç†
- èƒ½å¤Ÿè¿›è¡Œé¥æ“ä½œå’Œæ•°æ®é‡‡é›†

**é˜¶æ®µ 4ï¼šè®­ç»ƒæµç¨‹ï¼ˆ2-3 å¤©ï¼‰**

1. `src/lerobot/scripts/lerobot_train.py` - è®­ç»ƒè„šæœ¬
2. `src/lerobot/configs/train.py` - è®­ç»ƒé…ç½®
3. `src/lerobot/utils/train_utils.py` - è®­ç»ƒå·¥å…·
4. `examples/training/train_policy.py` - è®­ç»ƒç¤ºä¾‹

**å­¦ä¹ ç›®æ ‡**ï¿½?- ç†è§£å®Œæ•´è®­ç»ƒæµç¨‹
- æŒæ¡é…ç½®ç®¡ç†
- èƒ½å¤Ÿè‡ªå®šä¹‰è®­ç»ƒé€»è¾‘

#### å¿…è¯»æ–‡ä»¶

| æ–‡ä»¶ | é‡è¦ï¿½?| è¯´æ˜ |
|------|--------|------|
| `src/lerobot/__init__.py` | â­â­â­â­ï¿½?| é¡¹ç›®å…¥å£ï¼Œäº†è§£å¯ç”¨ç»„ï¿½?|
| `src/lerobot/policies/pretrained.py` | â­â­â­â­ï¿½?| ç­–ç•¥åŸºç±»ï¼Œæ ¸å¿ƒæ¥ï¿½?|
| `src/lerobot/datasets/lerobot_dataset.py` | â­â­â­â­ï¿½?| æ•°æ®é›†å®ï¿½?|
| `src/lerobot/robots/robot.py` | â­â­â­â­ | æœºå™¨äººæ¥ï¿½?|
| `src/lerobot/processor/pipeline.py` | â­â­â­â­ | æ•°æ®å¤„ç†ç®¡é“ |

#### å¯é€‰æ–‡ä»¶ï¼ˆæŒ‰éœ€é˜…è¯»ï¿½?
- `src/lerobot/rl/` - å¼ºåŒ–å­¦ä¹ ç›¸å…³
- `src/lerobot/async_inference/` - å¼‚æ­¥æ¨ç†
- `src/lerobot/envs/` - ä»¿çœŸç¯å¢ƒ
- `benchmarks/` - æ€§èƒ½æµ‹è¯•

### 3.2 æ ¸å¿ƒæ¦‚å¿µç†è§£

#### å…³é”®æœ¯è¯­è§£é‡Š

| æœ¯è¯­ | è§£é‡Š |
|------|------|
| **Episode** | ä¸€ä¸ªå®Œæ•´çš„ä»»åŠ¡æ‰§è¡Œåºåˆ—ï¼Œä»åˆå§‹çŠ¶æ€åˆ°ç»ˆæ­¢çŠ¶ï¿½?|
| **Observation** | æœºå™¨äººçš„è§‚æµ‹æ•°æ®ï¼ˆå›¾åƒã€å…³èŠ‚çŠ¶æ€ç­‰ï¿½?|
| **Action** | æœºå™¨äººçš„åŠ¨ä½œï¼ˆå…³èŠ‚ä½ç½®ã€é€Ÿåº¦ç­‰ï¼‰ |
| **Chunk** | åŠ¨ä½œåºåˆ—ç‰‡æ®µï¼ŒACT æ¨¡å‹ä¸€æ¬¡é¢„æµ‹å¤šä¸ªåŠ¨ï¿½?|
| **Processor** | æ•°æ®å¤„ç†å™¨ï¼Œè´Ÿè´£å½’ä¸€åŒ–ã€è½¬æ¢ç­‰æ“ä½œ |
| **Policy** | ç­–ç•¥æ¨¡å‹ï¼Œä»è§‚æµ‹æ˜ å°„åˆ°åŠ¨ï¿½?|
| **Teleoperator** | é¥æ“ä½œè®¾å¤‡ï¼Œç”¨äºäººç±»ç¤ºæ•™ |

#### æ ¸å¿ƒç®—æ³•ï¼šACT (Action Chunking Transformer)

**åŸç†**ï¿½?- ä½¿ç”¨ Transformer ç¼–ç å™¨å¤„ç†è§‚ï¿½?- CVAEï¼ˆæ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ï¼‰å­¦ä¹ åŠ¨ä½œåˆ†å¸ƒ
- ä¸€æ¬¡é¢„æµ‹å¤šä¸ªæœªæ¥åŠ¨ä½œï¼ˆchunkï¿½?
**æ•°å­¦è¡¨ç¤º**ï¿½?
\\\
è§‚æµ‹: o_t = {å›¾åƒ, çŠ¶æ€}
åŠ¨ä½œåºåˆ—: a_{t:t+T} = [a_t, a_{t+1}, ..., a_{t+T}]
ç­–ç•¥: Ï€(a_{t:t+T} | o_t, z)
å…¶ä¸­ z ~ N(Î¼(o_t), Ïƒ(o_t))
\\\

**ä»£ç å®ç°**ï¿½?
```python
# src/lerobot/policies/act/modeling_act.py
class ACTPolicy(PreTrainedPolicy):
    def forward(self, batch):
        # ç¼–ç è§‚æµ‹
        obs_features = self.encoder(batch['observation'])
        
        # CVAE ç¼–ç åŠ¨ä½œ
        mu, log_sigma = self.vae_encoder(batch['action'])
        z = mu + torch.exp(log_sigma) * torch.randn_like(mu)
        
        # è§£ç åŠ¨ä½œåºåˆ—
        action_pred = self.decoder(obs_features, z)
        
        return {'action': action_pred, 'mu': mu, 'log_sigma': log_sigma}
```

#### æ ¸å¿ƒç®—æ³•ï¼šDiffusion Policy

**åŸç†**ï¿½?- å°†åŠ¨ä½œç”Ÿæˆå»ºæ¨¡ä¸ºæ‰©æ•£è¿‡ç¨‹
- ä»å™ªå£°é€æ­¥å»å™ªå¾—åˆ°åŠ¨ä½œ
- ä½¿ç”¨ U-Net é¢„æµ‹å™ªå£°

**æ‰©æ•£è¿‡ç¨‹**ï¿½?
\\\
å‰å‘è¿‡ç¨‹: a_t = ï¿½?Î±_t) * a_0 + ï¿½?1-Î±_t) * Îµ
åå‘è¿‡ç¨‹: a_{t-1} = (a_t - ï¿½?1-Î±_t) * Îµ_Î¸(a_t, o, t)) / ï¿½?Î±_t)
\\\

#### æ•°æ®å¤„ç†ç®¡é“

**Pipeline å·¥ä½œæµç¨‹**ï¿½?
```mermaid
flowchart LR
    A[åŸå§‹æ•°æ®] --> B[ObservationProcessor]
    B --> C[NormalizeProcessor]
    C --> D[DeviceProcessor]
    D --> E[å¤„ç†åæ•°æ®]
    
    style A fill:#ffe6e6
    style E fill:#e6ffe6
```

**ç¤ºä¾‹ä»£ç **ï¿½?
```python
from lerobot.processor import DataProcessorPipeline
from lerobot.processor import NormalizeProcessor, DeviceProcessor

# åˆ›å»ºå¤„ç†ç®¡é“
pipeline = DataProcessorPipeline([
    NormalizeProcessor(stats={'mean': 0.5, 'std': 0.5}),
    DeviceProcessor(device='cuda')
])

# å¤„ç†æ•°æ®
processed_data = pipeline(raw_data)
```

#### ç†è®ºåŸºç¡€ä¸å‚è€ƒèµ„ï¿½?
**è®ºæ–‡**ï¿½?- ACT: [Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware](https://arxiv.org/abs/2304.13705)
- Diffusion Policy: [Diffusion Policy: Visuomotor Policy Learning via Action Diffusion](https://arxiv.org/abs/2303.04137)
- VQ-BeT: [Behavior Generation with Latent Actions](https://arxiv.org/abs/2403.03181)

**æ¨èèµ„æº**ï¿½?- [LeRobot å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/lerobot)
- [Robot Learning Tutorial](https://huggingface.co/spaces/lerobot/robot-learning-tutorial)
- [åŒæµå­è±ªå…„ä¸­æ–‡æ•™ç¨‹](https://zihao-ai.feishu.cn/wiki/space/7589642043471924447)


### 3.3 äºŒæ¬¡å¼€å‘æŒ‡ï¿½?
#### å¯æ‰©å±•ç‚¹

**1. è‡ªå®šä¹‰ç­–ç•¥æ¨¡ï¿½?*

åˆ›å»ºæ–°ç­–ç•¥éœ€è¦å®ç°ä»¥ä¸‹æ¥å£ï¼š

```python
# my_policy/modeling_my_policy.py
from lerobot.policies.pretrained import PreTrainedPolicy

class MyPolicy(PreTrainedPolicy):
    name = "my_policy"
    
    def __init__(self, config):
        super().__init__(config)
        # åˆå§‹åŒ–æ¨¡å‹ç»„ï¿½?        self.encoder = ...
        self.decoder = ...
    
    def forward(self, batch: dict) -> dict:
        \"\"\"è®­ç»ƒæ—¶çš„å‰å‘ä¼ æ’­\"\"\"
        obs = batch['observation']
        action = batch['action']
        
        # æ¨¡å‹è®¡ç®—
        pred_action = self.decoder(self.encoder(obs))
        
        # è®¡ç®—æŸå¤±
        loss = F.mse_loss(pred_action, action)
        
        return {'loss': loss, 'action': pred_action}
    
    def select_action(self, observation: dict) -> torch.Tensor:
        \"\"\"æ¨ç†æ—¶é€‰æ‹©åŠ¨ä½œ\"\"\"
        with torch.no_grad():
            obs_tensor = self._prepare_observation(observation)
            action = self.decoder(self.encoder(obs_tensor))
        return action
```

**é…ç½®ï¿½?*ï¿½?
```python
# my_policy/configuration_my_policy.py
from dataclasses import dataclass
from lerobot.configs.policies import PolicyConfig

@dataclass
class MyPolicyConfig(PolicyConfig):
    name: str = "my_policy"
    hidden_dim: int = 256
    num_layers: int = 4
```

**æ³¨å†Œç­–ç•¥**ï¿½?
```python
# my_policy/__init__.py
from lerobot.policies.factory import register_policy
from .modeling_my_policy import MyPolicy
from .configuration_my_policy import MyPolicyConfig

register_policy("my_policy", MyPolicy, MyPolicyConfig)
```

**2. è‡ªå®šä¹‰æœºå™¨äºº**

```python
# my_robot/my_robot.py
from lerobot.robots.robot import Robot
from lerobot.robots.config import RobotConfig

class MyRobot(Robot):
    name = "my_robot"
    config_class = RobotConfig
    
    def connect(self):
        \"\"\"è¿æ¥æœºå™¨äººç¡¬ä»¶\"\"\"
        # åˆå§‹åŒ–ä¸²å£ã€ç½‘ç»œè¿æ¥ç­‰
        self.serial = Serial('/dev/ttyUSB0', 115200)
    
    def disconnect(self):
        \"\"\"æ–­å¼€è¿æ¥\"\"\"
        self.serial.close()
    
    def get_observation(self) -> dict:
        \"\"\"è·å–è§‚æµ‹\"\"\"
        # è¯»å–ä¼ æ„Ÿå™¨æ•°ï¿½?        joint_positions = self._read_joint_positions()
        images = self._capture_images()
        
        return {
            'observation.state': joint_positions,
            'observation.images.cam0': images
        }
    
    def send_action(self, action: torch.Tensor):
        \"\"\"å‘é€åŠ¨ä½œ\"\"\"
        # è½¬æ¢ä¸ºç¡¬ä»¶æŒ‡ï¿½?        joint_commands = action.cpu().numpy()
        self._write_joint_commands(joint_commands)
    
    @property
    def observation_features(self) -> dict:
        return {
            'observation.state': (6,),  # 6 ä¸ªå…³ï¿½?            'observation.images.cam0': (480, 640, 3)
        }
```

**3. è‡ªå®šä¹‰æ•°æ®å¤„ç†å™¨**

```python
# my_processor.py
from lerobot.processor.core import ProcessorStep
from lerobot.processor.pipeline import ProcessorStepRegistry

@ProcessorStepRegistry.register("my_processor")
class MyProcessor(ProcessorStep):
    def __init__(self, param1: float = 1.0):
        self.param1 = param1
    
    def __call__(self, data: dict) -> dict:
        # è‡ªå®šä¹‰å¤„ç†é€»è¾‘
        data['processed_value'] = data['raw_value'] * self.param1
        return data
    
    def to_dict(self) -> dict:
        return {'param1': self.param1}
    
    @classmethod
    def from_dict(cls, config: dict):
        return cls(**config)
```

#### è´¡çŒ®è§„èŒƒä¸å¼€å‘æµï¿½?
**å¼€å‘ç¯å¢ƒè®¾ï¿½?*ï¿½?
```powershell
# å…‹éš†ä»“åº“
git clone https://github.com/huggingface/lerobot.git
cd lerobot

# å®‰è£…å¼€å‘ä¾ï¿½?pip install -e .[dev,test]

# å®‰è£… pre-commit hooks
pre-commit install
```

**ä»£ç è§„èŒƒ**ï¿½?
1. **æ ¼å¼ï¿½?*ï¼šä½¿ï¿½?Ruff è¿›è¡Œä»£ç æ ¼å¼ï¿½?
```powershell
# æ ¼å¼åŒ–ä»£ï¿½?ruff format .

# æ£€æŸ¥ä»£ç é£ï¿½?ruff check .
```

2. **ç±»å‹æ³¨è§£**ï¼šä½¿ï¿½?mypy è¿›è¡Œç±»å‹æ£€ï¿½?
```powershell
mypy src/lerobot
```

3. **æ–‡æ¡£å­—ç¬¦ï¿½?*ï¼šä½¿ï¿½?Google é£æ ¼

```python
def my_function(param1: int, param2: str) -> bool:
    \"\"\"ç®€çŸ­æè¿°å‡½æ•°åŠŸèƒ½ï¿½?    
    è¯¦ç»†æè¿°å‡½æ•°çš„è¡Œä¸ºå’Œç”¨é€”ï¿½?    
    Args:
        param1: å‚æ•°1çš„æï¿½?        param2: å‚æ•°2çš„æï¿½?    
    Returns:
        è¿”å›å€¼çš„æè¿°
    
    Raises:
        ValueError: ä½•æ—¶æŠ›å‡ºæ­¤å¼‚ï¿½?    \"\"\"
    pass
```

**æäº¤æµç¨‹**ï¿½?
1. åˆ›å»ºåˆ†æ”¯

```powershell
git checkout -b feature/my-new-feature
```

2. ç¼–å†™ä»£ç å’Œæµ‹ï¿½?
```python
# tests/test_my_feature.py
import pytest
from lerobot.my_module import my_function

def test_my_function():
    result = my_function(param1=10, param2="test")
    assert result == expected_value
```

3. è¿è¡Œæµ‹è¯•

```powershell
pytest tests/test_my_feature.py -v
```

4. æäº¤ä»£ç 

```powershell
git add .
git commit -m "feat: add my new feature"
git push origin feature/my-new-feature
```

5. åˆ›å»º Pull Request

#### è°ƒè¯•æŠ€ï¿½?
**1. ä½¿ç”¨ Rerun å¯è§†ï¿½?*

```python
import rerun as rr

# åˆå§‹ï¿½?Rerun
rr.init("my_debug_session", spawn=True)

# è®°å½•æ•°æ®
rr.log("observation/image", rr.Image(image))
rr.log("action", rr.Scalar(action_value))
```

**2. æ•°æ®é›†è°ƒï¿½?*

```powershell
# å¯è§†åŒ–æ•°æ®é›†
lerobot-dataset-viz --repo-id=my_dataset

# æ£€æŸ¥æ•°æ®é›†ç»Ÿè®¡
python -c "
from lerobot.datasets import LeRobotDataset
dataset = LeRobotDataset('my_dataset')
print(dataset.stats)
"
```

**3. ç­–ç•¥è°ƒè¯•**

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥æ¨¡å‹è¾“ï¿½?policy.eval()
with torch.no_grad():
    output = policy(batch)
    print(f"Output keys: {output.keys()}")
    print(f"Action shape: {output['action'].shape}")
```

**4. ä½¿ç”¨ debugpy è¿œç¨‹è°ƒè¯•**

```python
# åœ¨ä»£ç ä¸­æ’å…¥æ–­ç‚¹
import debugpy
debugpy.listen(5678)
print("Waiting for debugger...")
debugpy.wait_for_client()
```

#### æµ‹è¯•æ–¹æ³•

**å•å…ƒæµ‹è¯•**ï¿½?
```python
# tests/test_my_policy.py
import pytest
import torch
from lerobot.policies.my_policy import MyPolicy

@pytest.fixture
def policy():
    config = MyPolicyConfig()
    return MyPolicy(config)

def test_forward_pass(policy):
    batch = {
        'observation': torch.randn(8, 3, 224, 224),
        'action': torch.randn(8, 6)
    }
    output = policy(batch)
    assert 'loss' in output
    assert output['action'].shape == (8, 6)

def test_select_action(policy):
    observation = {'image': torch.randn(1, 3, 224, 224)}
    action = policy.select_action(observation)
    assert action.shape == (1, 6)
```

**é›†æˆæµ‹è¯•**ï¿½?
```python
# tests/integration/test_training.py
def test_training_pipeline():
    # åˆ›å»ºå°æ•°æ®é›†
    dataset = create_dummy_dataset()
    
    # è®­ç»ƒå‡ æ­¥
    policy = MyPolicy(config)
    for batch in dataset:
        output = policy(batch)
        loss = output['loss']
        loss.backward()
    
    # éªŒè¯æ¨¡å‹æ›´æ–°
    assert policy.encoder.weight.grad is not None
```

#### äºŒæ¬¡å¼€å‘ç¤ºï¿½?
**ç¤ºä¾‹ 1ï¼šæ·»åŠ æ–°çš„å›¾åƒå¢ï¿½?*

```python
# my_transforms.py
from lerobot.datasets.transforms import ImageTransform

class MyCustomTransform(ImageTransform):
    def __init__(self, strength: float = 0.5):
        self.strength = strength
    
    def __call__(self, image: np.ndarray) -> np.ndarray:
        # è‡ªå®šä¹‰å›¾åƒå¤„ï¿½?        processed = image * self.strength
        return processed.astype(np.uint8)

# ä½¿ç”¨
from lerobot.datasets import LeRobotDataset

dataset = LeRobotDataset(
    "my_dataset",
    image_transforms=[MyCustomTransform(strength=0.8)]
)
```

**ç¤ºä¾‹ 2ï¼šè‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡**

```python
# my_metrics.py
def compute_success_rate(predictions, ground_truth, threshold=0.05):
    \"\"\"è®¡ç®—æˆåŠŸç‡\"\"\"
    errors = torch.abs(predictions - ground_truth)
    success = (errors < threshold).all(dim=-1)
    return success.float().mean().item()

# åœ¨è¯„ä¼°ä¸­ä½¿ç”¨
from lerobot.scripts.lerobot_eval import eval_policy

results = eval_policy(
    policy=policy,
    env=env,
    n_episodes=50,
    custom_metrics={'success_rate': compute_success_rate}
)
print(f"Success rate: {results['success_rate']:.2%}")
```

**ç¤ºä¾‹ 3ï¼šå®ç°è‡ªå®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨**

```python
# my_scheduler.py
from torch.optim.lr_scheduler import _LRScheduler

class WarmupCosineScheduler(_LRScheduler):
    def __init__(self, optimizer, warmup_steps, total_steps):
        self.warmup_steps = warmup_steps
        self.total_steps = total_steps
        super().__init__(optimizer)
    
    def get_lr(self):
        if self.last_epoch < self.warmup_steps:
            # çº¿æ€§é¢„ï¿½?            alpha = self.last_epoch / self.warmup_steps
        else:
            # ä½™å¼¦é€€ï¿½?            progress = (self.last_epoch - self.warmup_steps) / (self.total_steps - self.warmup_steps)
            alpha = 0.5 * (1 + math.cos(math.pi * progress))
        
        return [base_lr * alpha for base_lr in self.base_lrs]

# ä½¿ç”¨
optimizer = torch.optim.Adam(policy.parameters(), lr=1e-3)
scheduler = WarmupCosineScheduler(optimizer, warmup_steps=1000, total_steps=100000)
```

**æ£€æŸ¥æ¸…ï¿½?*ï¿½?- [ ] ä»£ç ç¬¦åˆ PEP 8 è§„èŒƒ
- [ ] æ·»åŠ äº†ç±»å‹æ³¨ï¿½?- [ ] ç¼–å†™äº†å•å…ƒæµ‹ï¿½?- [ ] æ·»åŠ äº†æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] é€šè¿‡ï¿½?pre-commit æ£€ï¿½?- [ ] æ›´æ–°äº†ç›¸å…³æ–‡ï¿½?
---

## é™„å½•

### A. å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

| å‘½ä»¤ | åŠŸèƒ½ |
|------|------|
| `lerobot-info` | æŸ¥çœ‹ç‰ˆæœ¬ä¿¡æ¯ |
| `lerobot-find-cameras` | æŸ¥æ‰¾å¯ç”¨ç›¸æœº |
| `lerobot-find-port` | æŸ¥æ‰¾ä¸²å£è®¾å¤‡ |
| `lerobot-calibrate` | æ ¡å‡†æœºå™¨ï¿½?|
| `lerobot-teleoperate` | é¥æ“ä½œæœºå™¨äºº |
| `lerobot-record` | è®°å½•æ•°æ®ï¿½?|
| `lerobot-replay` | å›æ”¾æ•°æ®ï¿½?|
| `lerobot-train` | è®­ç»ƒç­–ç•¥ |
| `lerobot-eval` | è¯„ä¼°ç­–ç•¥ |
| `lerobot-dataset-viz` | å¯è§†åŒ–æ•°æ®é›† |

### B. é…ç½®æ–‡ä»¶æ¨¡æ¿

**å®Œæ•´è®­ç»ƒé…ç½®**ï¼ˆ`	rain_config.yaml`ï¼‰ï¼š

```yaml
# ç­–ç•¥é…ç½®
policy:
  name: act
  n_obs_steps: 1
  chunk_size: 100
  n_action_steps: 100
  dim_model: 512
  n_heads: 8
  dim_feedforward: 3200
  n_encoder_layers: 4
  n_decoder_layers: 7
  kl_weight: 10.0

# æ•°æ®é›†é…ï¿½?dataset:
  repo_id: lerobot/aloha_sim_transfer_cube_human
  root: null
  split: train
  image_transforms:
    enable: true
    max_num_transforms: 3
    random_crop: true
    brightness: [0.8, 1.2]
    contrast: [0.8, 1.2]

# è®­ç»ƒé…ç½®
training:
  offline_steps: 100000
  batch_size: 8
  lr: 1e-4
  lr_scheduler: cosine
  warmup_steps: 1000
  grad_clip_norm: 10
  weight_decay: 1e-4
  save_checkpoint: true
  save_freq: 10000
  log_freq: 100
  use_amp: false

# è¯„ä¼°é…ç½®
eval:
  n_episodes: 10
  batch_size: 10
  use_async_envs: false

# è¾“å‡ºé…ç½®
output_dir: outputs/act_training
wandb:
  enable: true
  project: lerobot
  entity: my_username
```

### C. æ•…éšœæ’æŸ¥æŒ‡å—

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|----------|----------|
| è®­ç»ƒæŸå¤±ä¸ä¸‹ï¿½?| å­¦ä¹ ç‡è¿‡ï¿½?è¿‡å° | è°ƒæ•´å­¦ä¹ ç‡ï¼Œå°è¯• 1e-5 ï¿½?1e-3 |
| GPU å†…å­˜æº¢å‡º | æ‰¹æ¬¡å¤§å°è¿‡å¤§ | å‡å° batch_size æˆ–å¯ç”¨æ¢¯åº¦ç´¯ï¿½?|
| æ•°æ®åŠ è½½ï¿½?| è§†é¢‘è§£ç ç“¶é¢ˆ | å¢åŠ  num_workers æˆ–ä½¿ç”¨å›¾åƒæ ¼ï¿½?|
| æœºå™¨äººè¿æ¥å¤±ï¿½?| ç«¯å£æƒé™/é©±åŠ¨é—®é¢˜ | æ£€æŸ¥è®¾å¤‡ç®¡ç†å™¨ï¼Œæ›´æ–°é©±ï¿½?|
| æ¨¡å‹æ¨ç†ï¿½?| æœªä½¿ï¿½?GPU | ç¡®ä¿ `device='cuda'` |

### D. æ€§èƒ½ä¼˜åŒ–å»ºè®®

**è®­ç»ƒåŠ ï¿½?*ï¿½?
```yaml
# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
training:
  use_amp: true

# å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
dataset:
  num_workers: 4
  prefetch_factor: 2

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
training:
  batch_size: 4
  gradient_accumulation_steps: 2  # ç­‰æ•ˆ batch_size=8
```

**æ¨ç†åŠ ï¿½?*ï¿½?
```python
# ä½¿ç”¨ TorchScript
policy_scripted = torch.jit.script(policy)

# ä½¿ç”¨åŠç²¾ï¿½?policy.half()

# æ‰¹é‡æ¨ç†
actions = policy.select_action_batch(observations)
```

### E. èµ„æºé“¾æ¥

- **å®˜æ–¹ç½‘ç«™**: https://huggingface.co/lerobot
- **GitHub**: https://github.com/huggingface/lerobot
- **æ–‡æ¡£**: https://huggingface.co/docs/lerobot
- **Discord**: https://discord.gg/q8Dzzpym3f
- **è®ºå›**: https://discuss.huggingface.co/c/lerobot
- **ä¸­æ–‡æ•™ç¨‹**: https://zihao-ai.feishu.cn/wiki/space/7589642043471924447

---

## æ€»ç»“

æœ¬æ–‡æ¡£æ¶µç›–äº† LeRobot é¡¹ç›®çš„å®Œæ•´æŠ€æœ¯æ¶æ„ã€å¿«é€Ÿä¸Šæ‰‹æŒ‡å—å’Œæ·±å…¥å­¦ä¹ è·¯çº¿ã€‚é€šè¿‡æœ¬æ–‡æ¡£ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿï¼š

ï¿½?ç†è§£ LeRobot çš„æ•´ä½“æ¶æ„å’Œæ¨¡å—èŒè´£  
ï¿½?å¿«é€Ÿæ­å»ºå¼€å‘ç¯å¢ƒå¹¶è¿è¡Œç¤ºä¾‹  
ï¿½?æŒæ¡è®­ç»ƒã€è¯„ä¼°å’Œæ•°æ®é‡‡é›†æµç¨‹  
ï¿½?è¿›è¡ŒäºŒæ¬¡å¼€å‘å’Œè‡ªå®šä¹‰æ‰©ï¿½? 

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒå®˜æ–¹æ–‡æ¡£æˆ–ï¿½?Discord ç¤¾åŒºå¯»æ±‚å¸®åŠ©ï¿½?
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´ï¿½?*: 2026-02-15  
**ç»´æŠ¤ï¿½?*: LeRobot Community

---

**License**: Apache 2.0  
**Copyright**: Â© 2024-2026 Hugging Face Inc.
