# æ•…éšœæ’æŸ¥æŒ‡å—

> å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

---

## ğŸ“‹ ç›®å½•

1. [å®‰è£…é—®é¢˜](#å®‰è£…é—®é¢˜)
2. [CUDA å’Œ GPU é—®é¢˜](#cuda-å’Œ-gpu-é—®é¢˜)
3. [å†…å­˜é—®é¢˜](#å†…å­˜é—®é¢˜)
4. [è®­ç»ƒé—®é¢˜](#è®­ç»ƒé—®é¢˜)
5. [æ•°æ®é—®é¢˜](#æ•°æ®é—®é¢˜)
6. [CRaFT ç‰¹å®šé—®é¢˜](#craft-ç‰¹å®šé—®é¢˜)
7. [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)

---

## å®‰è£…é—®é¢˜

### é—®é¢˜ 1: pip install å¤±è´¥

**ç—‡çŠ¶**:
```
ERROR: Could not find a version that satisfies the requirement lerobot
```

**åŸå› **: PyPI ä¸Šå¯èƒ½æ²¡æœ‰æœ€æ–°ç‰ˆæœ¬

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä»æºç å®‰è£…
git clone <your-repo-url>
cd lerobot
pip install -e .
```

### é—®é¢˜ 2: ä¾èµ–å†²çª

**ç—‡çŠ¶**:
```
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# åˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒ
conda create -n lerobot_clean python=3.10
conda activate lerobot_clean

# é‡æ–°å®‰è£…
pip install -e .
```

### é—®é¢˜ 3: ç¼ºå°‘ç³»ç»Ÿä¾èµ–

**ç—‡çŠ¶**:
```
ImportError: libGL.so.1: cannot open shared object file
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y libgl1-mesa-glx libglib2.0-0

# CentOS/RHEL
sudo yum install -y mesa-libGL glib2
```

---

## CUDA å’Œ GPU é—®é¢˜

### é—®é¢˜ 1: CUDA ä¸å¯ç”¨

**ç—‡çŠ¶**:
```python
>>> import torch
>>> torch.cuda.is_available()
False
```

**è¯Šæ–­**:
```bash
# æ£€æŸ¥ NVIDIA é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥ PyTorch CUDA ç‰ˆæœ¬
python -c "import torch; print(torch.version.cuda)"
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å®‰è£…å¯¹åº” CUDA ç‰ˆæœ¬çš„ PyTorch
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# CPU only
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### é—®é¢˜ 2: CUDA Out of Memory

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**è§£å†³æ–¹æ¡ˆ 1: å‡å° batch_size**
```bash
# ä» 8 å‡åˆ° 4
--batch_size=4
```

**è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯**
```bash
# ç­‰æ•ˆ batch_size=8ï¼Œä½†æ˜¾å­˜å ç”¨å‡åŠ
--batch_size=4 --gradient_accumulation_steps=2
```

**è§£å†³æ–¹æ¡ˆ 3: ä½¿ç”¨æ··åˆç²¾åº¦**
```bash
--use_amp=true
```

**è§£å†³æ–¹æ¡ˆ 4: æ¸…ç† GPU ç¼“å­˜**
```python
import torch
torch.cuda.empty_cache()
```

### é—®é¢˜ 3: GPU åˆ©ç”¨ç‡ä½

**ç—‡çŠ¶**: GPU åˆ©ç”¨ç‡ < 50%

**åŸå› **: æ•°æ®åŠ è½½ç“¶é¢ˆ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹
--num_workers=4

# å¯ç”¨ pin_memory
--pin_memory=true

# ä½¿ç”¨æ›´å¿«çš„æ•°æ®æ ¼å¼ï¼ˆMP4 è€Œéå›¾åƒåºåˆ—ï¼‰
```

---

## å†…å­˜é—®é¢˜

### é—®é¢˜ 1: CPU å†…å­˜ä¸è¶³

**ç—‡çŠ¶**:
```
MemoryError: Unable to allocate array
```

**è§£å†³æ–¹æ¡ˆ 1: å‡å°‘æ•°æ®é›†ç¼“å­˜**
```bash
# ä¸ç¼“å­˜æ•´ä¸ªæ•°æ®é›†
--dataset.cache=false
```

**è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨æµå¼åŠ è½½**
```bash
--dataset.streaming=true
```

**è§£å†³æ–¹æ¡ˆ 3: å‡å°‘ num_workers**
```bash
--num_workers=2  # ä» 4 å‡åˆ° 2
```

### é—®é¢˜ 2: æ•°æ®é›†ä¸‹è½½å ç”¨å¤§é‡ç©ºé—´

**ç—‡çŠ¶**: ç£ç›˜ç©ºé—´ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```bash
# è®¾ç½®ç¼“å­˜ç›®å½•åˆ°å¤§å®¹é‡ç£ç›˜
export HF_HOME=/path/to/large/disk

# æˆ–åœ¨ä»£ç ä¸­æŒ‡å®š
--dataset.root=/path/to/large/disk/datasets
```

---

## è®­ç»ƒé—®é¢˜

### é—®é¢˜ 1: è®­ç»ƒä¸æ”¶æ•›

**ç—‡çŠ¶**: æŸå¤±ä¸ä¸‹é™æˆ–éœ‡è¡

**è¯Šæ–­**:
```python
# æ£€æŸ¥å­¦ä¹ ç‡
print(f"Learning rate: {optimizer.param_groups[0]['lr']}")

# æ£€æŸ¥æ¢¯åº¦èŒƒæ•°
print(f"Gradient norm: {grad_norm}")

# æ£€æŸ¥æ•°æ®ç»Ÿè®¡
from lerobot.datasets import LeRobotDataset
dataset = LeRobotDataset("...")
print(dataset.stats)
```

**è§£å†³æ–¹æ¡ˆ 1: è°ƒæ•´å­¦ä¹ ç‡**
```bash
# å­¦ä¹ ç‡è¿‡å¤§
--training.lr=5e-5  # ä» 1e-4 é™åˆ° 5e-5

# å­¦ä¹ ç‡è¿‡å°
--training.lr=3e-4  # ä» 1e-4 å‡åˆ° 3e-4
```

**è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨**
```bash
--training.lr_scheduler=cosine
--training.warmup_steps=1000
```

**è§£å†³æ–¹æ¡ˆ 3: æ£€æŸ¥æ•°æ®å½’ä¸€åŒ–**
```python
# ç¡®ä¿æ•°æ®å·²æ­£ç¡®å½’ä¸€åŒ–
print(f"Mean: {dataset.stats['observation.state']['mean']}")
print(f"Std: {dataset.stats['observation.state']['std']}")
```

### é—®é¢˜ 2: æ¢¯åº¦çˆ†ç‚¸

**ç—‡çŠ¶**:
```
Step 100/10000 | loss=nan | grdn=inf
```

**è§£å†³æ–¹æ¡ˆ 1: å¯ç”¨æ¢¯åº¦è£å‰ª**
```bash
--training.grad_clip_norm=10
```

**è§£å†³æ–¹æ¡ˆ 2: é™ä½å­¦ä¹ ç‡**
```bash
--training.lr=1e-5
```

**è§£å†³æ–¹æ¡ˆ 3: æ£€æŸ¥æ•°æ®è´¨é‡**
```python
# æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
import torch
batch = next(iter(dataloader))
print(f"Max value: {batch['observation'].max()}")
print(f"Min value: {batch['observation'].min()}")
print(f"Has NaN: {torch.isnan(batch['observation']).any()}")
```

### é—®é¢˜ 3: è®­ç»ƒé€Ÿåº¦æ…¢

**ç—‡çŠ¶**: æ¯æ­¥è€—æ—¶ > 1 ç§’

**è¯Šæ–­**:
```python
import time

# æµ‹é‡æ•°æ®åŠ è½½æ—¶é—´
start = time.time()
batch = next(iter(dataloader))
print(f"Data loading: {time.time() - start:.3f}s")

# æµ‹é‡å‰å‘ä¼ æ’­æ—¶é—´
start = time.time()
output = model(batch)
print(f"Forward pass: {time.time() - start:.3f}s")

# æµ‹é‡åå‘ä¼ æ’­æ—¶é—´
start = time.time()
loss.backward()
print(f"Backward pass: {time.time() - start:.3f}s")
```

**è§£å†³æ–¹æ¡ˆ**: è§ [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)

---

## æ•°æ®é—®é¢˜

### é—®é¢˜ 1: æ•°æ®é›†ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**:
```
ConnectionError: Failed to download dataset from HuggingFace Hub
```

**è§£å†³æ–¹æ¡ˆ 1: ä½¿ç”¨é•œåƒ**
```bash
export HF_ENDPOINT=https://hf-mirror.com
```

**è§£å†³æ–¹æ¡ˆ 2: æ‰‹åŠ¨ä¸‹è½½**
```bash
# ä» HuggingFace Hub æ‰‹åŠ¨ä¸‹è½½
# ç„¶åæŒ‡å®šæœ¬åœ°è·¯å¾„
--dataset.root=/path/to/local/dataset
```

**è§£å†³æ–¹æ¡ˆ 3: ä½¿ç”¨ä»£ç†**
```bash
export HTTP_PROXY=http://proxy.example.com:8080
export HTTPS_PROXY=http://proxy.example.com:8080
```

### é—®é¢˜ 2: æ•°æ®é›†æ ¼å¼é”™è¯¯

**ç—‡çŠ¶**:
```
KeyError: 'observation.images.top'
```

**è¯Šæ–­**:
```python
from lerobot.datasets import LeRobotDataset

dataset = LeRobotDataset("...")
print(f"Available keys: {dataset[0].keys()}")
print(f"Features: {dataset.features}")
```

**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥æ•°æ®é›†æ˜¯å¦ä¸º LeRobotDataset v3 æ ¼å¼

### é—®é¢˜ 3: è§†é¢‘è§£ç å¤±è´¥

**ç—‡çŠ¶**:
```
RuntimeError: Failed to decode video frame
```

**è§£å†³æ–¹æ¡ˆ 1: é‡æ–°ç¼–ç è§†é¢‘**
```bash
# ä½¿ç”¨ ffmpeg é‡æ–°ç¼–ç 
ffmpeg -i input.mp4 -c:v libx264 -preset slow -crf 18 output.mp4
```

**è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨å›¾åƒæ ¼å¼**
```bash
# è½¬æ¢ä¸ºå›¾åƒåºåˆ—
--dataset.image_format=png
```

---

## CRaFT ç‰¹å®šé—®é¢˜

### é—®é¢˜ 1: AnchorCache åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
FileNotFoundError: AnchorCache directory not found: data/anchor_hidden_cache
```

**è¯Šæ–­**:
```bash
# æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
ls -lh data/anchor_hidden_cache/

# æ£€æŸ¥æ–‡ä»¶
ls -lh data/anchor_hidden_cache/*.pt
ls -lh data/anchor_hidden_cache/metadata.json
```

**è§£å†³æ–¹æ¡ˆ**: é‡æ–°ç”Ÿæˆ cache
```bash
python -m lerobot.scripts.build_anchor_hidden_cache \
    --dataset.repo_id=lerobot/aloha_sim_insertion_human \
    --policy.path=lerobot/pi0_fast \
    --output_dir=data/anchor_hidden_cache \
    --num_samples=1000
```

### é—®é¢˜ 2: Retention mode ä¸åŒ¹é…

**ç—‡çŠ¶**:
```
ValueError: retention_mode=hidden éœ€è¦ hidden feature cacheï¼Œä½† anchor_batch ä¸åŒ…å« 'target_features'
```

**åŸå› **: Cache ç±»å‹ä¸ retention_mode ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¦‚æœä½¿ç”¨ hidden modeï¼Œéœ€è¦ hidden feature cache
python -m lerobot.scripts.build_anchor_hidden_cache ...

# å¦‚æœä½¿ç”¨ token_ce modeï¼Œéœ€è¦ token-level cache
python -m lerobot.scripts.build_anchor_cache ...
```

### é—®é¢˜ 3: æ¢¯åº¦å†²çªè¿‡å¤š

**ç—‡çŠ¶**: æ—¥å¿—ä¸­ `conflict=âœ“` å‡ºç°é¢‘ç‡ > 50%

**è¯Šæ–­**:
```bash
# æ£€æŸ¥æ¢¯åº¦ç‚¹ç§¯å’Œä½™å¼¦ç›¸ä¼¼åº¦
# å¦‚æœ dot å’Œ cos ç»å¸¸ä¸ºè´Ÿï¼Œè¯´æ˜å†²çªä¸¥é‡
```

**è§£å†³æ–¹æ¡ˆ 1: è°ƒæ•´å†²çªé˜ˆå€¼**
```bash
# æ”¾å®½é˜ˆå€¼
craft.conflict_threshold=-0.2  # ä» -0.1 æ”¹ä¸º -0.2
```

**è§£å†³æ–¹æ¡ˆ 2: è°ƒæ•´ Î»**
```bash
# é™ä½ä¿ç•™æŸå¤±æƒé‡
craft.initial_lambda=0.5  # ä» 1.0 é™åˆ° 0.5
```

**è§£å†³æ–¹æ¡ˆ 3: è°ƒæ•´ Îµ**
```bash
# æ”¾å®½ä¿ç•™çº¦æŸ
craft.epsilon_start=1.5  # ä» 1.0 å‡åˆ° 1.5
```

### é—®é¢˜ 4: Î» å¢é•¿è¿‡å¿«

**ç—‡çŠ¶**: Î» å¿«é€Ÿè¾¾åˆ° Î»_max

**åŸå› **: ä¿ç•™æŸå¤±æŒç»­è¿åçº¦æŸ

**è§£å†³æ–¹æ¡ˆ 1: é™ä½ Î» å­¦ä¹ ç‡**
```bash
craft.lambda_lr=0.005  # ä» 0.01 é™åˆ° 0.005
```

**è§£å†³æ–¹æ¡ˆ 2: å¢å¤§ Î»_max**
```bash
craft.lambda_max=20.0  # ä» 10.0 å‡åˆ° 20.0
```

**è§£å†³æ–¹æ¡ˆ 3: è°ƒæ•´ Îµ è°ƒåº¦**
```bash
# æ›´æ…¢çš„é€€ç«
craft.epsilon_decay_steps=20000  # ä» 10000 å‡åˆ° 20000
```

---

## æ€§èƒ½é—®é¢˜

### é—®é¢˜ 1: æ•°æ®åŠ è½½æ…¢

**ç—‡çŠ¶**: `data_s` > 0.5 ç§’

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¢åŠ  num_workers
--num_workers=4

# å¯ç”¨ prefetch
--prefetch_factor=2

# ä½¿ç”¨ SSD å­˜å‚¨æ•°æ®é›†
```

### é—®é¢˜ 2: å‰å‘ä¼ æ’­æ…¢

**ç—‡çŠ¶**: `updt_s` > 1.0 ç§’

**è§£å†³æ–¹æ¡ˆ 1: ä½¿ç”¨æ··åˆç²¾åº¦**
```bash
--use_amp=true
```

**è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨ TorchScript**
```python
policy_scripted = torch.jit.script(policy)
```

**è§£å†³æ–¹æ¡ˆ 3: ä½¿ç”¨æ›´å°çš„æ¨¡å‹**
```bash
# ä½¿ç”¨æ›´å°çš„ hidden_dim
--policy.dim_model=256  # ä» 512 é™åˆ° 256
```

### é—®é¢˜ 3: ä¿å­˜ checkpoint æ…¢

**ç—‡çŠ¶**: ä¿å­˜ checkpoint è€—æ—¶ > 30 ç§’

**è§£å†³æ–¹æ¡ˆ 1: å‡å°‘ä¿å­˜é¢‘ç‡**
```bash
--training.save_freq=5000  # ä» 1000 å‡åˆ° 5000
```

**è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨æ›´å¿«çš„å­˜å‚¨**
```bash
# ä¿å­˜åˆ° SSD
--output_dir=/path/to/ssd/outputs
```

**è§£å†³æ–¹æ¡ˆ 3: å¼‚æ­¥ä¿å­˜**
```python
# åœ¨åå°çº¿ç¨‹ä¿å­˜
import threading

def save_checkpoint_async(checkpoint, path):
    thread = threading.Thread(target=torch.save, args=(checkpoint, path))
    thread.start()
```

---

## è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### 2. ä½¿ç”¨ pdb è°ƒè¯•

```python
import pdb

# åœ¨ä»£ç ä¸­æ’å…¥æ–­ç‚¹
pdb.set_trace()
```

### 3. ä½¿ç”¨ Rerun å¯è§†åŒ–

```python
import rerun as rr

rr.init("debug_session", spawn=True)
rr.log("observation/image", rr.Image(image))
rr.log("action", rr.Scalar(action_value))
```

### 4. æ£€æŸ¥å¼ é‡ç»Ÿè®¡

```python
def check_tensor(tensor, name="tensor"):
    print(f"{name}:")
    print(f"  Shape: {tensor.shape}")
    print(f"  Dtype: {tensor.dtype}")
    print(f"  Device: {tensor.device}")
    print(f"  Min: {tensor.min().item():.4f}")
    print(f"  Max: {tensor.max().item():.4f}")
    print(f"  Mean: {tensor.mean().item():.4f}")
    print(f"  Std: {tensor.std().item():.4f}")
    print(f"  Has NaN: {torch.isnan(tensor).any().item()}")
    print(f"  Has Inf: {torch.isinf(tensor).any().item()}")
```

### 5. æ€§èƒ½åˆ†æ

```python
import torch.profiler as profiler

with profiler.profile(
    activities=[
        profiler.ProfilerActivity.CPU,
        profiler.ProfilerActivity.CUDA,
    ],
    record_shapes=True,
    profile_memory=True,
) as prof:
    # è¿è¡Œä»£ç 
    output = model(batch)
    loss = output['loss']
    loss.backward()

print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
```

---

## è·å–å¸®åŠ©

å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½æ— æ³•è§£å†³é—®é¢˜ï¼š

1. **æŸ¥çœ‹æ—¥å¿—**: å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯
2. **æœ€å°å¤ç°**: åˆ›å»ºæœ€å°å¯å¤ç°ç¤ºä¾‹
3. **æäº¤ Issue**: åœ¨ GitHub æäº¤è¯¦ç»†çš„ bug æŠ¥å‘Š
4. **ç¤¾åŒºè®¨è®º**: åœ¨ Discord æˆ–è®ºå›å¯»æ±‚å¸®åŠ©

### Issue æ¨¡æ¿

```markdown
**é—®é¢˜æè¿°**
ç®€è¦æè¿°é—®é¢˜

**å¤ç°æ­¥éª¤**
1. è¿è¡Œå‘½ä»¤ `...`
2. è§‚å¯Ÿåˆ°é”™è¯¯ `...`

**é¢„æœŸè¡Œä¸º**
åº”è¯¥å‘ç”Ÿä»€ä¹ˆ

**å®é™…è¡Œä¸º**
å®é™…å‘ç”Ÿäº†ä»€ä¹ˆ

**ç¯å¢ƒä¿¡æ¯**
- OS: Ubuntu 20.04
- Python: 3.10.12
- PyTorch: 2.2.1
- CUDA: 11.8
- GPU: RTX 3090

**é”™è¯¯æ—¥å¿—**
```
å®Œæ•´çš„é”™è¯¯å †æ ˆ
```

**å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ**
- å°è¯•äº† Xï¼Œç»“æœ Y
- å°è¯•äº† Zï¼Œç»“æœ W
```

---

## å¸¸è§é”™è¯¯ä»£ç 

| é”™è¯¯ä»£ç  | è¯´æ˜ | è§£å†³æ–¹æ¡ˆ |
|----------|------|----------|
| `CUDA_ERROR_OUT_OF_MEMORY` | GPU å†…å­˜ä¸è¶³ | å‡å° batch_size |
| `RuntimeError: CUDA error: device-side assert triggered` | CUDA æ–­è¨€å¤±è´¥ | æ£€æŸ¥ç´¢å¼•è¶Šç•Œ |
| `KeyError: 'observation.images.top'` | æ•°æ®é›†é”®ä¸å­˜åœ¨ | æ£€æŸ¥æ•°æ®é›†æ ¼å¼ |
| `FileNotFoundError` | æ–‡ä»¶ä¸å­˜åœ¨ | æ£€æŸ¥è·¯å¾„ |
| `ConnectionError` | ç½‘ç»œè¿æ¥å¤±è´¥ | ä½¿ç”¨é•œåƒæˆ–ä»£ç† |
| `ValueError: retention_mode` | é…ç½®é”™è¯¯ | æ£€æŸ¥ retention_mode |

---

**æœ€åæ›´æ–°**: 2026-02-17

**æç¤º**: å¦‚æœé‡åˆ°æ–°é—®é¢˜ï¼Œæ¬¢è¿æäº¤ PR æ›´æ–°æœ¬æ–‡æ¡£ï¼

