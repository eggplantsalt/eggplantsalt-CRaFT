# MCQ Likelihood Evaluation - å®ç°æ€»ç»“

## âœ… é˜¶æ®µ 5 å®Œæˆ

### ä»»åŠ¡ç›®æ ‡
åˆ›å»ºä¸€ä¸ªè¯„æµ‹è„šæœ¬ï¼Œä½¿ç”¨ forward logitsï¼ˆè€Œé generateï¼‰è®¡ç®—å¤šé€‰é¢˜ç­”æ¡ˆæ¦‚ç‡ã€‚

---

## ğŸ“ æ–°å¢æ–‡ä»¶

### 1. æ ¸å¿ƒè„šæœ¬
**æ–‡ä»¶**: `src/lerobot/scripts/eval_mcq_likelihood.py` (çº¦ 400 è¡Œ)

**åŠŸèƒ½**:
- åŠ è½½ JSONL æ ¼å¼çš„å¤šé€‰é¢˜æ•°æ®
- å¯¹æ¯ä¸ªé€‰é¡¹è®¡ç®— log P(choice_tokens | image+question)
- ä½¿ç”¨ teacher forcing ç´¯åŠ  token log-probability
- é€‰æ‹© log-likelihood æœ€å¤§çš„é€‰é¡¹ä½œä¸ºé¢„æµ‹
- è¾“å‡º accuracy å’Œ average margin (top1-top2)
- æ”¯æŒå¯¹æ¯”ä¸¤ä¸ª checkpoint

**æ ¸å¿ƒå‡½æ•°**:
```python
def compute_choice_loglikelihood(policy, image_tensor, question_text, choice_text, device):
    """è®¡ç®—å•ä¸ª choice çš„ log-likelihood"""
    # 1. æ„é€  prompt: "{question}\nAnswer: {choice}"
    # 2. Tokenize
    # 3. Embed prefix (image + tokens)
    # 4. Forward pass è·å– logits
    # 5. è®¡ç®— choice tokens çš„ log-probability
    # 6. ç´¯åŠ å¾—åˆ°æ€» log-likelihood
    return log_likelihood

def evaluate_sample(policy, sample, device):
    """è¯„æµ‹å•ä¸ªæ ·æœ¬"""
    # 1. åŠ è½½å›¾åƒ
    # 2. å¯¹æ¯ä¸ª choice è®¡ç®— log-likelihood
    # 3. é€‰æ‹©æœ€å¤§çš„ä½œä¸ºé¢„æµ‹
    # 4. è®¡ç®— margin (top1 - top2)
    return predicted_index, log_likelihoods, correct, margin

def evaluate_checkpoint(checkpoint_path, data_jsonl, max_samples, batch_size, device):
    """è¯„æµ‹å•ä¸ª checkpoint"""
    # 1. åŠ è½½ policy
    # 2. åŠ è½½æ•°æ®
    # 3. é€æ ·æœ¬è¯„æµ‹
    # 4. è®¡ç®— accuracy å’Œ avg_margin
    return results

def compare_checkpoints(checkpoint_a, checkpoint_b, ...):
    """å¯¹æ¯”ä¸¤ä¸ª checkpoint"""
    # 1. åˆ†åˆ«è¯„æµ‹ä¸¤ä¸ª checkpoint
    # 2. è¾“å‡ºå¯¹æ¯”ç»“æœ
    return results_a, results_b
```

### 2. Smoke Test
**æ–‡ä»¶**: `tests/test_mcq_likelihood_smoke.py` (çº¦ 200 è¡Œ)

**åŠŸèƒ½**:
- åˆ›å»ºæµ‹è¯•å›¾åƒå’Œ JSONL æ•°æ®
- éªŒè¯æ•°æ®åŠ è½½å’Œæ ¼å¼
- éªŒè¯å›¾åƒé¢„å¤„ç†
- Mock evaluation ç»“æ„éªŒè¯

**æµ‹è¯•ç”¨ä¾‹**:
```python
def test_mcq_likelihood_smoke():
    """æ•°æ®åŠ è½½å’Œæ ¼å¼éªŒè¯"""
    # 1. åˆ›å»ºä¸´æ—¶æµ‹è¯•æ•°æ®ï¼ˆ2 æ¡æ ·æœ¬ï¼‰
    # 2. éªŒè¯ JSONL æ ¼å¼
    # 3. éªŒè¯å›¾åƒåŠ è½½
    # 4. éªŒè¯ tensor shape å’Œ dtype

def test_mcq_likelihood_mock_evaluation():
    """Mock evaluation ç»“æ„éªŒè¯"""
    # 1. åˆ›å»º mock policy
    # 2. éªŒè¯åŸºæœ¬ç»“æ„
```

### 3. æ–‡æ¡£
**æ–‡ä»¶**: `docs/MCQ_LIKELIHOOD_EVAL.md` (çº¦ 400 è¡Œ)

**å†…å®¹**:
- ä½¿ç”¨æ–¹æ³•ï¼ˆåŸºç¡€è¯„æµ‹ã€å¯¹æ¯”è¯„æµ‹ã€ä¿å­˜ç»“æœï¼‰
- æ•°æ®æ ¼å¼ï¼ˆJSONL æ ¼å¼è¯´æ˜å’Œç¤ºä¾‹ï¼‰
- è¯„æµ‹åŸç†ï¼ˆlog-likelihood è®¡ç®—ã€margin è®¡ç®—ï¼‰
- è¾“å‡ºæŒ‡æ ‡ï¼ˆaccuracy, avg_marginï¼‰
- ä½¿ç”¨åœºæ™¯ï¼ˆè¯„æµ‹ CRaFTã€æŒç»­å­¦ä¹ ã€å¿«é€ŸéªŒè¯ï¼‰
- æ³¨æ„äº‹é¡¹å’Œæ•…éšœæ’é™¤

### 4. ç¤ºä¾‹æ•°æ®
**æ–‡ä»¶**: `data/mcq_test_sample.jsonl` (2 æ¡æ ·æœ¬)

```jsonl
{"image_path": "...", "question": "...", "choices": [...], "answer_index": 0}
{"image_path": "...", "question": "...", "choices": [...], "answer_index": 2}
```

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. Teacher Forcing è®¡ç®—
ä¸ä½¿ç”¨ `generate()`ï¼Œè€Œæ˜¯ï¼š
```python
# 1. æ„é€ å®Œæ•´åºåˆ—ï¼šimage + question + "Answer: " + choice
# 2. Forward pass è·å– logits
# 3. æå– choice tokens å¯¹åº”ä½ç½®çš„ logits
# 4. è®¡ç®— log P(choice_tokens | prefix)
# 5. ç´¯åŠ å¾—åˆ°æ€» log-likelihood
```

### 2. é€‰é¡¹é€‰æ‹©
```python
# å¯¹æ¯ä¸ª choice è®¡ç®— log-likelihood
log_likelihoods = [compute_choice_loglikelihood(...) for choice in choices]

# é€‰æ‹©æœ€å¤§çš„
predicted_index = argmax(log_likelihoods)
```

### 3. Margin è®¡ç®—
```python
# è¡¡é‡æ¨¡å‹ç½®ä¿¡åº¦
sorted_logliks = sorted(log_likelihoods, reverse=True)
margin = sorted_logliks[0] - sorted_logliks[1]
```

### 4. åŒ Checkpoint å¯¹æ¯”
```python
# è¯„æµ‹ä¸¤ä¸ª checkpoint
results_a = evaluate_checkpoint(checkpoint_a, ...)
results_b = evaluate_checkpoint(checkpoint_b, ...)

# è¾“å‡ºå·®å¼‚
print(f"Accuracy: {results_b['accuracy'] - results_a['accuracy']:.2%}")
print(f"Avg Margin: {results_b['avg_margin'] - results_a['avg_margin']:.4f}")
```

---

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è¯„æµ‹
```bash
python -m lerobot.scripts.eval_mcq_likelihood \
    --checkpoint_path=outputs/model_checkpoint \
    --data_jsonl=data/mcq_test.jsonl \
    --max_samples=100
```

**è¾“å‡º**:
```
================================================================================
è¯„æµ‹ç»“æœ
================================================================================
Checkpoint: outputs/model_checkpoint
Accuracy: 85.00%
Average Margin (top1 - top2): 2.3456
Correct: 85/100
```

### å¯¹æ¯”è¯„æµ‹
```bash
python -m lerobot.scripts.eval_mcq_likelihood \
    --checkpoint_path=outputs/baseline \
    --checkpoint_path_b=outputs/craft_trained \
    --data_jsonl=data/mcq_test.jsonl
```

**è¾“å‡º**:
```
================================================================================
å¯¹æ¯”ç»“æœ
================================================================================
Checkpoint A: outputs/baseline
  Accuracy: 75.00%
  Avg Margin: 1.8234
  Correct: 75/100

Checkpoint B: outputs/craft_trained
  Accuracy: 85.00%
  Avg Margin: 2.3456
  Correct: 85/100

å·®å¼‚:
  Accuracy: +10.00%
  Avg Margin: +0.5222
```

### Smoke Test
```bash
python tests/test_mcq_likelihood_smoke.py
```

**è¾“å‡º**:
```
================================================================================
MCQ Likelihood Evaluation - Smoke Test
================================================================================

[Test 1] Data loading and format validation
âœ“ Smoke test passed!
  - Loaded 2 samples
  - Image shape: torch.Size([3, 224, 224])
  - Sample format validated

[Test 2] Mock evaluation structure
âœ“ Mock evaluation structure validated!

================================================================================
All smoke tests passed! âœ“
================================================================================
```

---

## ğŸ”§ æŠ€æœ¯å®ç°

### 1. å›¾åƒé¢„å¤„ç†
```python
def load_image(image_path, image_size=(224, 224)):
    img = Image.open(image_path).convert("RGB")
    img = img.resize(image_size)
    img_array = np.array(img).astype(np.float32) / 255.0
    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)
    return img_tensor  # [C, H, W], [0, 1]
```

### 2. Prompt æ„é€ 
```python
prompt = f"{question_text}\nAnswer: {choice_text}"
tokens = tokenizer.encode(prompt, add_special_tokens=False, return_tensors="pt")
```

### 3. Forward Pass
```python
# Embed prefix (image + tokens + BOS)
prefix_embs, prefix_pad_masks, prefix_att_masks, _, _ = \
    policy.model.embed_prefix_fast(images, img_masks, tokens_with_bos, masks_with_bos)

# Forward pass
position_ids = torch.cumsum(prefix_pad_masks, dim=1) - 1
att_4d = policy.model._prepare_attention_masks_4d(prefix_att_masks, dtype=prefix_embs.dtype)

(prefix_out, _), _ = policy.model.paligemma_with_expert.forward(
    attention_mask=att_4d,
    position_ids=position_ids,
    inputs_embeds=[prefix_embs, None],
    use_cache=False,
)

# Get logits
logits = lm_head(prefix_out)  # [1, seq_len, vocab_size]
```

### 4. Log-Likelihood è®¡ç®—
```python
# æå– choice tokens å¯¹åº”çš„ logits
choice_logits = logits[:, -(num_choice_tokens+1):-1, :]

# è®¡ç®— log probabilities
log_probs = F.log_softmax(choice_logits, dim=-1)

# æå–ç›®æ ‡ token çš„ log prob
target_log_probs = log_probs.gather(dim=-1, index=choice_targets.unsqueeze(-1)).squeeze(-1)

# ç´¯åŠ 
log_likelihood = target_log_probs.sum().item()
```

---

## ğŸ“ˆ åº”ç”¨åœºæ™¯

### 1. è¯„æµ‹ CRaFT è®­ç»ƒæ•ˆæœ
å¯¹æ¯”è®­ç»ƒå‰åæ¨¡å‹åœ¨å¤šé€‰é¢˜ä¸Šçš„è¡¨ç°ï¼š
```bash
python -m lerobot.scripts.eval_mcq_likelihood \
    --checkpoint_path=outputs/baseline \
    --checkpoint_path_b=outputs/craft_trained \
    --data_jsonl=data/mcq_test.jsonl
```

### 2. è¯„æµ‹æŒç»­å­¦ä¹ èƒ½åŠ›
è¯„æµ‹æ¨¡å‹åœ¨æ—§ä»»åŠ¡ä¸Šçš„ä¿ç•™èƒ½åŠ›ï¼š
```bash
python -m lerobot.scripts.eval_mcq_likelihood \
    --checkpoint_path=outputs/after_new_task \
    --data_jsonl=data/old_task_mcq.jsonl
```

### 3. å¿«é€ŸéªŒè¯
ä½¿ç”¨å°‘é‡æ ·æœ¬å¿«é€ŸéªŒè¯æ¨¡å‹ï¼š
```bash
python -m lerobot.scripts.eval_mcq_likelihood \
    --checkpoint_path=outputs/model \
    --data_jsonl=data/mcq_test.jsonl \
    --max_samples=10
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å½“å‰é™åˆ¶
- **é€æ ·æœ¬è¯„æµ‹**: å½“å‰å®ç°ä¸ºé€æ ·æœ¬è¯„æµ‹ï¼ˆbatch_size å‚æ•°ä¿ç•™ç”¨äºæœªæ¥ä¼˜åŒ–ï¼‰
- **Token å¯¹é½**: å‡è®¾ choice tokens åœ¨åºåˆ—æœ«å°¾ï¼Œå¦‚æœ tokenization æ–¹å¼ä¸åŒå¯èƒ½éœ€è¦è°ƒæ•´
- **å†…å­˜ä½¿ç”¨**: æ¯æ¬¡ forward pass éƒ½é‡æ–°è®¡ç®—å®Œæ•´åºåˆ—

### 2. æœªæ¥ä¼˜åŒ–
- æ”¯æŒ batch è¯„æµ‹ä»¥æé«˜é€Ÿåº¦
- æ”¯æŒ KV cache ä»¥å‡å°‘é‡å¤è®¡ç®—
- æ”¯æŒæ›´çµæ´»çš„ prompt æ ¼å¼
- æ·»åŠ æ›´å¤šè¯„æµ‹æŒ‡æ ‡ï¼ˆentropy, confidence ç­‰ï¼‰

### 3. ä¾èµ–
- Pi0Fast policy å¿…é¡»å·²åŠ è½½
- å›¾åƒæ–‡ä»¶å¿…é¡»å­˜åœ¨ä¸”å¯è¯»
- JSONL æ ¼å¼å¿…é¡»æ­£ç¡®

---

## ğŸ“¦ Git æäº¤

```bash
Commit: ad3f4dce
Message: feat: add MCQ likelihood eval script for pi0_fast

Files changed: 3
Insertions: 990
- src/lerobot/scripts/eval_mcq_likelihood.py (æ–°å¢)
- tests/test_mcq_likelihood_smoke.py (æ–°å¢)
- docs/MCQ_LIKELIHOOD_EVAL.md (æ–°å¢)
- data/mcq_test_sample.jsonl (æ–°å¢)
```

**æœªæ‰§è¡Œ push**ï¼ˆæŒ‰è¦æ±‚ï¼‰

---

## âœ… å®Œæˆæ¸…å•

- [x] åˆ›å»º `eval_mcq_likelihood.py` è„šæœ¬
- [x] å®ç° log-likelihood è®¡ç®—ï¼ˆteacher forcingï¼‰
- [x] å®ç°å• checkpoint è¯„æµ‹
- [x] å®ç°åŒ checkpoint å¯¹æ¯”
- [x] è¾“å‡º accuracy å’Œ avg_margin
- [x] åˆ›å»º smoke testï¼ˆ2 æ¡æ ·ä¾‹ï¼‰
- [x] åˆ›å»ºå®Œæ•´æ–‡æ¡£
- [x] åˆ›å»ºç¤ºä¾‹ JSONL æ•°æ®
- [x] Git commitï¼ˆæœª pushï¼‰

---

## ğŸ‰ é˜¶æ®µ 5 å®Œæˆï¼

MCQ likelihood è¯„æµ‹è„šæœ¬å·²å®Œæˆï¼Œå¯ç”¨äºè¯„æµ‹ Pi0Fast æ¨¡å‹åœ¨å¤šé€‰é¢˜ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œç‰¹åˆ«é€‚åˆè¯„æµ‹ CRaFT è®­ç»ƒæ•ˆæœå’ŒæŒç»­å­¦ä¹ èƒ½åŠ›ã€‚

