{
  "test_suite": "CRaFT Training Framework",
  "created": "2026-02-15",
  "tests": [
    {
      "id": "grad_surgery_math",
      "name": "Gradient Surgery Math Operations",
      "status": "passing",
      "priority": "high",
      "description": "Unit tests for gradient dot product, projection, and merging operations",
      "file": "tests/test_grad_surgery_math.py",
      "test_cases": [
        "test_compute_dot_positive",
        "test_compute_dot_negative",
        "test_project_if_conflict_no_conflict",
        "test_project_if_conflict_with_conflict",
        "test_merge_grads_weighted",
        "test_merge_grads_equal",
        "test_gradient_surgery_end_to_end"
      ],
      "dependencies": [
        "grad_surgery.py implementation"
      ],
      "notes": "grad_surgery.py 已完整实现（compute_dot, project_if_conflict, merge_grads）"
    },
    {
      "id": "train_craft_dryrun",
      "name": "CRaFT Training Dry-Run",
      "status": "ready_for_testing",
      "priority": "high",
      "description": "Validate that lerobot_train_craft.py can load policy and run complete training loop",
      "file": "src/lerobot/scripts/lerobot_train_craft.py",
      "command": "bash scripts/train_craft_dryrun.sh",
      "expected_output": "完整训练循环（3 步），包含任务损失和保留损失（如果提供 AnchorCache）",
      "dependencies": [
        "policy loading",
        "dataset loading",
        "preprocessor setup",
        "AnchorCache loading (optional)"
      ],
      "notes": "完整训练流程已实现，包括双分支训练、梯度手术、原对偶优化"
    },
    {
      "id": "primal_dual_logic",
      "name": "Primal-Dual Optimization Logic",
      "status": "passing",
      "priority": "medium",
      "description": "Test epsilon scheduling and lambda update logic",
      "file": "tests/test_primal_dual.py",
      "test_cases": [
        "test_epsilon_schedule_linear",
        "test_epsilon_schedule_cosine",
        "test_update_lambda_increase",
        "test_update_lambda_decrease",
        "test_lambda_clipping"
      ],
      "dependencies": [
        "primal_dual.py implementation"
      ],
      "notes": "primal_dual.py 已完整实现（epsilon_schedule, update_lambda）"
    },
    {
      "id": "retention_loss_computation",
      "name": "Retention Loss Computation",
      "status": "not_started",
      "priority": "medium",
      "description": "Test retention loss computation on anchor data",
      "file": "tests/test_retention_loss.py",
      "test_cases": [
        "test_compute_retention_loss_basic",
        "test_retention_loss_matches_policy_forward"
      ],
      "dependencies": [
        "retention_loss.py implementation",
        "anchor_cache.py implementation"
      ]
    },
    {
      "id": "anchor_dataloader",
      "name": "Anchor Dataset Loading",
      "status": "passing",
      "priority": "medium",
      "description": "Test anchor dataset loading and batching",
      "file": "tests/test_anchor_cache.py",
      "test_cases": [
        "test_labels_mask_rules",
        "test_anchor_cache_dataset_format",
        "test_anchor_cache_dataloader",
        "test_anchor_cache_cross_shard_access",
        "test_labels_no_loss_on_padding"
      ],
      "dependencies": [
        "anchor_cache.py implementation"
      ],
      "notes": "使用 mock 数据测试，验证 labels mask 规则和数据格式正确性"
    },
    {
      "id": "craft_training_integration",
      "name": "CRaFT Training Integration Test",
      "status": "ready_for_testing",
      "priority": "high",
      "description": "End-to-end test of CRaFT training with dual backward passes",
      "file": "tests/test_craft_training.py",
      "test_cases": [
        "test_update_policy_craft_single_step",
        "test_lambda_updates_over_steps",
        "test_gradient_surgery_applied",
        "test_retention_constraint_enforced"
      ],
      "dependencies": [
        "All CRaFT modules implemented",
        "lerobot_train_craft.py fully functional"
      ],
      "notes": "所有依赖已完成，可以在真实数据集上进行端到端测试"
    }
  ],
  "implementation_phases": [
    {
      "phase": 1,
      "name": "Scaffold (Current)",
      "status": "completed",
      "tasks": [
        "Create craft package structure",
        "Create lerobot_train_craft.py with dry-run mode",
        "Create test file skeletons",
        "Document key file paths"
      ]
    },
    {
      "phase": 2,
      "name": "Core Algorithms",
      "status": "completed",
      "tasks": [
        "Implement grad_surgery.py functions",
        "Implement primal_dual.py functions",
        "Implement retention_loss.py (使用 policy.forward)",
        "Write unit tests for above"
      ]
    },
    {
      "phase": 3,
      "name": "Data Pipeline",
      "status": "completed",
      "tasks": [
        "Implement anchor_cache.py",
        "Integrate anchor dataloader in train_craft",
        "Test anchor data loading"
      ]
    },
    {
      "phase": 4,
      "name": "Training Loop",
      "status": "completed",
      "tasks": [
        "Implement dual backward passes in update_policy_craft",
        "Implement gradient extraction and setting",
        "Integrate gradient surgery and lambda updates",
        "Test full training loop"
      ]
    },
    {
      "phase": 5,
      "name": "Validation",
      "status": "ready_for_testing",
      "tasks": [
        "Run training on small dataset (需要在服务器上测试)",
        "Verify retention constraint is enforced",
        "Compare with baseline training",
        "Performance profiling"
      ]
    }
  ],
  "completed_features": [
    "完整的梯度手术算法（compute_dot, project_if_conflict, merge_grads）",
    "完整的原对偶优化（epsilon_schedule, update_lambda）",
    "完整的 CRaFT 训练循环（update_policy_craft, train_craft）",
    "AnchorCache 离线生成和加载（build_anchor_cache.py, anchor_cache.py）",
    "K-step 策略（每 K 步计算一次保留损失）",
    "分布式训练支持（retention_loss 跨进程平均）",
    "完整的日志记录（终端 + WandB）",
    "检查点保存和恢复（包含 CRaFT 状态）",
    "Lambda 历史导出（CSV 格式）",
    "训练脚本和文档（train_craft.sh, CRAFT_TRAINING_GUIDE.md）"
  ],
  "next_steps": [
    "在真实数据集上运行 build_anchor_cache.py",
    "在小规模数据集上运行完整训练（steps=1000）",
    "验证 λ 收敛行为和梯度冲突频率",
    "对比 baseline 和 CRaFT 的性能",
    "性能优化（如果训练速度过慢）"
  ],
  "notes": [
    "Baseline training (lerobot_train.py) must remain functional",
    "No modifications to pi0_fast policy implementation",
    "CRaFT modules are independent and testable",
    "Dry-run mode validates infrastructure before full implementation"
  ]
}

